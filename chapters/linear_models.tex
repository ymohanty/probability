
\chapter{Linear models \label{chap:linearModels}}
\begin{example}
\label{exa:isi2006samplepsb11}A straight line regression $\E(y)=\alpha+\beta x$
is to be fitted using four observations. Assume $\Var(y\mid x)=\sigma^{2}$
for all $x$. The values of $x$ at which observations are to be made
lie in the closed interval $[-1,1]$. The following choices of the
values of $x$ where observations are to be made are available:
\end{example}

\begin{enumerate}
\item two observations each at \$x=-1\$ and \$x=1\$,
\item one observation each at \$x=-1\$ and \$x=1\$ and two observations
at \$x=0\$,
\item one observation each at \$x=-1,-\textbackslash frac\{1\}\{2\}, \textbackslash frac\{1\}\{2\},
1\$.
\end{enumerate}
If the interest is to estimate the slope with least variance, which
of the above strategies would you choose and why? \hl{TODO}
\begin{example}
\label{exa:isi2007samplepsb12}Let $Y_{1},Y_{2}$ and $Y_{3}$ be
uncorrelated random variables with common variance $\sigma^{2}>0$
such that 
\[
E\left(Y_{1}\right)=\beta_{1}+\beta_{2},E\left(Y_{2}\right)=2\beta_{1}\text{ and }E\left(Y_{3}\right)=\beta_{1}-\beta_{2}
\]
 where $\beta_{1}$ and $\beta_{2}$ are unknown parameters. Find
the residual (error) sum of squares under the above linear model.\hl{TODO}
\end{example}


