#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsbook
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Independence and random variables
\end_layout

\begin_layout Standard
Formal probability theory is often described as measure theory (or more
 generally, analysis) on measure spaces 
\begin_inset Formula $\measurespace$
\end_inset

 where the 
\begin_inset Formula $\mu\left(\X\right)=1$
\end_inset

 and to a certain extent the foundational theory does resemble this characteriza
tion.
 However probability itself is distinct from foundational probability 
\emph on
theory
\emph default
, in that its goals and aims are to solve problems that are of a fundamentally
 different character than problems seen in analysis.
\end_layout

\begin_layout Standard
Probability as as subject has a strong combinatorial flavor, since it owes
 its origins to gambling and games of chance considered by amateur mathematician
s in the 17th and 18th centuries.
 These classical ideas still permeate the modern 
\emph on
probabilistic way of thinking.

\emph default
 As such, it would be useful to revise the basic combinatorial tools that
 are indispensable when tackling problems of this nature.
 These are discussed in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Combinatorics"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
In general, we can say that probability theory 
\begin_inset Quotes eld
\end_inset

has a right hand and a left hand
\begin_inset Quotes erd
\end_inset

.
 The right hand is the rigorous measure-theoretic axiomatization that one
 encounters in a course on probability theory.
 The left hand is the probablistic intuition that one develops through trying
 to model stochastic phenomena with the aforementioned probabilistic way
 of thinking.
 Probabilists aim to be ambidextrous in this regard, using the axiomatic
 framework of probability theory to deduce facts about processes whose parts
 and subparts can be reduced to “naïve” probabilistic concepts.
\end_layout

\begin_layout Standard
In order to cover both parts of probability adequately, we will use the
 background in analysis developed in Part I of these notes to prove general
 theorems, while using numerous examples to develop probabilistic intuition.
 I hope that the combination of theory and examples prove sufficient in
 painting a vivid picture of probability theory, with a view towards application
s in statistics and economics.
\end_layout

\begin_layout Section
Probability spaces and probability measures
\end_layout

\begin_layout Standard
While formal probability theory is based on measure theory, the language
 of probability theory is different.
 To start our exploration into probability theory, we shall first have to
 translate a lot of the basic terminology of measure theory into the langauge
 of probability.
 To begin with, we specialize the notion of a measure space 
\begin_inset Formula $\measurespace$
\end_inset

 to a probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

 where 
\begin_inset Formula $\mathbb{P}\left(\Omega\right)=1$
\end_inset

.
 Measurable sets 
\begin_inset Formula $A\in\F$
\end_inset

 are called 
\emph on
events 
\emph default
in the language of probability.
 The basic properties of probability measures carry over from Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:measures"
plural "false"
caps "false"
noprefix "false"

\end_inset

; we list a few more for completeness.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:inclusionExclusionProbability"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Inclusion-Exclusion
\end_layout

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}\in\F$
\end_inset

.
 Then
\begin_inset Formula 
\[
\mathbb{P}\left(\bigcup_{i=1}^{n}A_{i}\right)=\sum_{i=1}^{n}\left(-1\right)^{i-1}\sum_{J\subset\left\{ 1,2,\ldots n\right\} ,\lvert J\rvert=i}\mathbb{P}\left(\bigcap_{j\in J}A_{j}\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Integrate the equality 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inclusionExclusionIndicator"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:inclusionExclusion"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2017psa23"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2017 PSA 23
\end_layout

\end_inset

Three numbers are chosen at random from 
\begin_inset Formula $\{1,2,\ldots,10\}$
\end_inset

 without replacement.
 What is the probability that the minimum of the chosen numbers is 
\begin_inset Formula $3$
\end_inset

 or their maximum is 
\begin_inset Formula $7$
\end_inset

 ? Let 
\begin_inset Formula $A$
\end_inset

 be the event that we select three numbers with minimum 
\begin_inset Formula $3$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 be the event that we select three numbers with maximum 
\begin_inset Formula $7$
\end_inset

.
 We want 
\begin_inset Formula $\mathbb{P}\left(A\cup B\right)=\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)-\mathbb{P}\left(A\cap B\right).$
\end_inset

 We need to compute each component.
 To compute the first term, note that there are 
\begin_inset Formula $\left(\begin{array}{c}
7\\
2
\end{array}\right)$
\end_inset

 ways to pick 2 numbers without replacement after fixing the first one at
 3 since we are picking only from the remaining numbers which are greater
 than three.
 Therefore 
\begin_inset Formula $\mathbb{P}\left(A\right)=\left(\begin{array}{c}
7\\
2
\end{array}\right)/\left(\begin{array}{c}
10\\
3
\end{array}\right).$
\end_inset

 Similarly, we have that 
\begin_inset Formula $\mathbb{P}\left(B\right)=\left(\begin{array}{c}
6\\
2
\end{array}\right)/\left(\begin{array}{c}
10\\
3
\end{array}\right).$
\end_inset

 To find the intersection, note that after fixing 
\begin_inset Formula $3$
\end_inset

 and 
\begin_inset Formula $7$
\end_inset

 there are only 4 choices of the middle number, leaving us with 
\begin_inset Formula $\mathbb{P}\left(A\cap B\right)=$
\end_inset


\begin_inset Formula $4/\left(\begin{array}{c}
10\\
3
\end{array}\right)$
\end_inset

.
 In sum,
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\right) & =\frac{\left(\begin{array}{c}
7\\
2
\end{array}\right)+\left(\begin{array}{c}
6\\
2
\end{array}\right)-4}{\left(\begin{array}{c}
10\\
3
\end{array}\right)}\\
 & =\frac{21+15-4}{120}\\
 & =\frac{4}{15}.
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:bonferroniInequality"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}\in\F$
\end_inset

.
 Then
\begin_inset Formula 
\[
\mathbb{P}\left(\bigcap_{i=1}^{n}A_{i}\right)\geq\sum_{i=1}^{n}\mathbb{P}\left(A_{i}\right)-(n-1).
\]

\end_inset


\end_layout

\begin_layout Proof
First note that for 
\begin_inset Formula $n=2$
\end_inset

, the result follows due to the fact that for any 
\begin_inset Formula $A,B\in\F$
\end_inset


\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\right) & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)-\mathbb{P}\left(A\cap B\right)\\
 & \leq\mathbb{P}\left(\Omega\right)\\
 & =1.
\end{align*}

\end_inset

Now assume the induction hypothesis and note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\bigcap_{i=1}^{n}A_{i}\right) & =\mathbb{P}\left(\bigcap_{i=1}^{n-1}A_{i}\cap A_{n}\right)\\
 & \geq\mathbb{P}\left(\bigcap_{i=1}^{n-1}A_{i}\right)+\mathbb{P}\left(A_{n}\right)-1\\
 & \geq\sum_{i=1}^{n-1}\mathbb{P}\left(A_{i}\right)-(n-2)+\mathbb{P}\left(A_{n}\right)-1\\
 & =\sum_{i=1}^{n}\mathbb{P}\left(A_{i}\right)-\left(n-1\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Independent events
\end_layout

\begin_layout Standard
In Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:productMeasures"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we discussed the notion of product measures; the analagous concept in probabili
ty is that of independence.
 Informally, we think of independent events as those where the occurence
 or non-occurenece of one event does not impact the occurence or non-occurence
 of another.
 We can formalize this idea with the following definition-
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:independence"

\end_inset

Let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 Then a collection of events
\emph on
 
\emph default

\begin_inset Formula $\left\{ A_{i}\right\} _{i\in I}\subset\F$
\end_inset

 are independent if for every finite subset 
\begin_inset Formula $J\subset I$
\end_inset


\begin_inset Formula 
\[
\mathbb{P}\left[\bigcap_{j\in J}A_{j}\right]=\prod_{j\in J}\mathbb{P}\left[A_{j}\right].
\]

\end_inset

Two independent events 
\begin_inset Formula $A,B\in\F$
\end_inset

 are often denoted 
\begin_inset Formula $A\indep B$
\end_inset

.
\end_layout

\begin_layout Standard
Notice how the index set 
\begin_inset Formula $I$
\end_inset

 was arbitrary and so we can have countable or uncountable collections of
 independent events.
 Of course, this notion isn't particualrly interesting unless we have some
 rich examples of such events and the probability spaces they live in.
 More generally, we have a question of existence: do independent events
 always exist, no matter the probability space? The answer to this question
 is trivially yes since 
\begin_inset Formula $\mathbb{P}\left(\Omega\cap\emptyset\right)=\mathbb{P}\left(\Omega\right)\mathbb{P}\left(\emptyset\right)=0.$
\end_inset

 So then the question reduces to asking whether 
\emph on
non-trivial 
\emph default
independent events always exist.
 Here of course, the answer is 
\begin_inset Quotes eld
\end_inset

no
\begin_inset Quotes erd
\end_inset

, since for 
\begin_inset Formula $\F=\left\{ \emptyset,A,A^{C},\Omega\right\} $
\end_inset

 where 
\begin_inset Formula $0<\mathbb{P}\left(A\right)<1$
\end_inset

, we have that 
\begin_inset Formula $\mathbb{P}\left(A\cap A^{C}\right)=0$
\end_inset

 but 
\begin_inset Formula $\mathbb{P}\left(A\right)\mathbb{P}\left(A^{C}\right)=\mathbb{P}\left(A\right)\left(1-\mathbb{P}\left(A\right)\right)\neq0.$
\end_inset

 Nevertheless, we have a rich collection of examples of independent events:
 think about rolling a dice twice and observing a six in each roll; these
 event of seeing a six in the first roll is independent of the event of
 seeing one in the next roll.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2017psa15"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2017 PSA 15
\end_layout

\end_inset

Suppose that the events 
\begin_inset Formula $A,B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 are pairwise independent such that each of them occurs with probability
 
\begin_inset Formula $p$
\end_inset

.
 Assume that all three of them cannot occur simultaneously.
 What is 
\begin_inset Formula $P(A\cup B\cup C)$
\end_inset

 ? Well, we apply independence and inclusion exclusion to note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\cup C\right) & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)+\mathbb{P}\left(C\right)-\mathbb{P}\left(A\cap B\right)-\mathbb{P}\left(A\cap C\right)-\mathbb{P}\left(B\cap C\right)\\
 & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)+\mathbb{P}\left(C\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(B\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(C\right)-\mathbb{P}\left(B\right)\mathbb{P}\left(C\right)\\
 & =3p(1-p).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The canonical example of the an infinite collection of independent events
 is given by the following description of an infinitely repeated experiment.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:infinitelyRepeatedExperiment"

\end_inset

Let 
\begin_inset Formula $E$
\end_inset

 consist of a finite set of outcomes and let 
\begin_inset Formula $\Omega=E^{\N}$
\end_inset

 be the collection of 
\begin_inset Formula $E$
\end_inset

-valued sequences.
 Thus for any 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, we can write
\begin_inset Formula 
\[
\omega=\left(\omega_{1},\omega_{2},\ldots\right)
\]

\end_inset

where 
\begin_inset Formula $\omega_{i}\in E$
\end_inset

.
 We can then construct the collection
\begin_inset Formula 
\[
\left[\omega_{1}^{*},\ldots,\omega_{n}^{*}\right]:=\left\{ \omega\in\Omega\mid\omega_{i}=\omega_{i}^{*},1\leq i\leq n\right\} 
\]

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:independenceComplements"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A,B\in\F$
\end_inset

 be events.
 Then the claims that 
\begin_inset Formula $A,B$
\end_inset

 are independent, 
\begin_inset Formula $A,B^{C}$
\end_inset

 are independent, 
\begin_inset Formula $A^{C},B$
\end_inset

 are independent, and 
\begin_inset Formula $A^{C},B^{C}$
\end_inset

are independent are equivalent.
\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cap B^{C}\right) & =\mathbb{P}\left(A\setminus B\right)\\
 & =\mathbb{P}\left(A\setminus A\cap B\right)\\
 & =\mathbb{P}\left(A\right)-\mathbb{P}\left(A\cap B\right)\\
 & =\mathbb{P}\left(A\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(B\right)\\
 & =\mathbb{P}\left(A\right)\left(1-\mathbb{P}\left(B\right)\right)\\
 & =\mathbb{P}\left(A\right)\mathbb{P}\left(B^{C}\right)
\end{align*}

\end_inset

where the fourth equality uses independence.
 Then it should be clear that 
\begin_inset Formula $A^{C}$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are independent exactly for the same reason.
 Finally, we can apply the logic above using 
\begin_inset Formula $A^{C}$
\end_inset

and 
\begin_inset Formula $B$
\end_inset

 instead of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 to get that 
\begin_inset Formula $A^{C}$
\end_inset

 and 
\begin_inset Formula $B^{C}$
\end_inset

 are independent.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:independenceFacts"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 Let 
\begin_inset Formula $\left\{ A_{i}\right\} _{i\in I}\in\F$
\end_inset

 be a collection of events and define 
\begin_inset Formula $B_{i}^{1}=A_{i}^{C}$
\end_inset

 and 
\begin_inset Formula $B_{i}^{0}=A_{i}.$
\end_inset

 Then, the following statements are equivalent
\end_layout

\begin_layout Proposition
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{enumerate}[label=(
\backslash
roman*),leftmargin=.1
\backslash
linewidth,rightmargin=.4
\backslash
linewidth]
\end_layout

\begin_layout Plain Layout


\backslash
item $
\backslash
left
\backslash
{ A_{i}
\backslash
right
\backslash
} _{i
\backslash
in I}
\backslash
in
\backslash
F$ are independent events.
\end_layout

\begin_layout Plain Layout


\backslash
item There exists some $
\backslash
alpha 
\backslash
in 
\backslash
{0,1
\backslash
}^I$ such that $
\backslash
{B_i^{a(i)}
\backslash
}$ are independent.
\end_layout

\begin_layout Plain Layout


\backslash
item For every $
\backslash
alpha 
\backslash
in 
\backslash
{0,1
\backslash
}^I$, $
\backslash
{B_i^{a(i)}
\backslash
}$ are independent.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{enumerate}
\end_layout

\end_inset


\end_layout

\begin_layout Proof
(Sketch) Note that if 
\emph on
(i) 
\emph default
holds, then 
\emph on
(ii)
\emph default
 holds automatically with 
\begin_inset Formula $a\left(i\right)=0$
\end_inset

 for all 
\begin_inset Formula $i\in I$
\end_inset

.
 Similarly, if 
\begin_inset Formula $(iii)$
\end_inset

 holds then 
\begin_inset Formula $(i)$
\end_inset

 holds trivially.
 Thus we need to prove that 
\begin_inset Formula $(ii)\implies(iii)$
\end_inset

.
 First, fix 
\begin_inset Formula $\alpha\in\{0,1\}^{I}$
\end_inset

 such that our claim holds.
 Notice that by Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:independenceComplements"
plural "false"
caps "false"
noprefix "false"

\end_inset

, for any 
\begin_inset Formula $J\subset I$
\end_inset

 such that 
\begin_inset Formula $\lvert J\rvert=2$
\end_inset

,
\begin_inset Formula 
\[
\mathbb{P}\left(\prod_{j\in J}B_{j}^{\gamma(j)}\right)=\prod_{j\in J}\mathbb{P}\left(B_{j}^{\gamma\left(j\right)}\right)
\]

\end_inset

for any 
\begin_inset Formula $\gamma\in\left\{ 0,1\right\} ^{I}$
\end_inset

.
 For induction, suppose that the claim holds for any 
\begin_inset Formula $J\subset I$
\end_inset

 such that 
\begin_inset Formula $\lvert J\rvert=n$
\end_inset

 and the consider a subset 
\begin_inset Formula $J^{\prime}\subset I$
\end_inset

 with 
\begin_inset Formula $\lvert J^{\prime}\rvert=n+1$
\end_inset

.
 Note that for any 
\begin_inset Formula $i\in J^{\prime}$
\end_inset

, we can define 
\begin_inset Formula $B_{-i}:=\bigcap_{j\in J^{\prime}\setminus\left\{ i\right\} }B_{j}^{\alpha\left(j\right)}$
\end_inset

 and observe that 
\begin_inset Formula 
\[
\mathbb{P}\left(B_{-i}\cap B_{i}^{\alpha\left(i\right)}\right)=\mathbb{P}\left(B_{-i}\right)\mathbb{P}\left(B_{i}^{\alpha\left(i\right)}\right)
\]

\end_inset

and so 
\begin_inset Formula $B_{-i}\indep B_{i}^{\alpha\left(i\right)}$
\end_inset

 and so by our Lemma, 
\begin_inset Formula $B_{-i}\indep B_{i}^{\gamma\left(i\right)}.$
\end_inset

 The induction hypothesis then implies that 
\begin_inset Formula $\left\{ B_{j}^{\alpha\left(j\right)}\right\} ,B_{i}^{\gamma\left(i\right)}$
\end_inset

 are all mutually independent.
 We can yet again repeat this process with some 
\begin_inset Formula $i^{\prime}\in J^{\prime}$
\end_inset

 where now 
\begin_inset Formula $B_{-i^{\prime}}:=\bigcap_{j\in J^{\prime}\setminus\left\{ i,i^{\prime}\right\} }B_{j}^{\alpha\left(j\right)}\cap B_{i}^{\gamma\left(i\right)}$
\end_inset

 and so on until we have replaced all 
\begin_inset Formula $\alpha$
\end_inset

s with 
\begin_inset Formula $\gamma$
\end_inset

s.
\end_layout

\begin_layout Standard
This idea of mutual independence finds purchase in some unexpected contexts
 as well.
 For instance, we can use it to prove Euler's prime number formula.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:eulerPrime"

\end_inset

Let 
\begin_inset Formula $\mathcal{P}$
\end_inset

 denote the set of primes.
 The Riemann zeta function 
\begin_inset Formula 
\[
\zeta\left(s\right):=\sum_{n=1}^{\infty}n^{-s}
\]

\end_inset

has the representation
\begin_inset Formula 
\[
\zeta\left(s\right)=\prod_{p\in\mathcal{P}}\left(1-p^{-s}\right)^{-1}.
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\probabilityspace=\left(\N,2^{\N},\mathbb{P}_{s}\right)$
\end_inset

 where 
\begin_inset Formula $\mathbb{P}_{s}\left(\left\{ n\right\} \right)=\frac{n^{-s}}{\zeta\left(s\right)}$
\end_inset

 for 
\begin_inset Formula $s>1.$
\end_inset

 Define 
\begin_inset Formula $p\N:=\left\{ pn\mid n\in\N\right\} $
\end_inset

 and let 
\begin_inset Formula $ $
\end_inset

for any 
\begin_inset Formula $p\in\mathcal{P}$
\end_inset

 and notice that 
\begin_inset Formula $\mathbb{P}_{s}\left(p\N\right)=\sum_{n=1}^{\infty}\mathbb{P}\left(pn\right)=p^{-s}$
\end_inset

 by countable additivity.
 Then, for any distinct collection 
\begin_inset Formula $p_{1},\ldots,p_{k}\in\mathcal{P}$
\end_inset

 we have that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}_{s}\left(\bigcap_{i=1}^{k}p_{i}\N\right) & =\sum_{n=1}^{\infty}\mathbb{P}_{s}\left(\prod_{i=1}^{k}pn\right)\\
 & =\prod_{i=1}^{k}p^{-s}\\
 & =\prod_{i=1}^{k}\mathbb{P}_{s}\left(p_{i}\N\right).
\end{align*}

\end_inset

In other words, the events 
\begin_inset Formula $\left\{ p\N\right\} _{p\in\mathcal{P}}$
\end_inset

are mutually independent and so by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:independenceFacts"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset Formula 
\begin{align*}
\frac{1}{\zeta\left(s\right)} & =\mathbb{P}_{s}\left(\left\{ 1\right\} \right)\\
 & =\mathbb{P}_{s}\left(\bigcap_{p\in\mathcal{P}}\left(p\N\right)^{C}\right)\\
 & =\lim_{n\to\infty}\mathbb{P}_{s}\left(\bigcap_{p\in\mathcal{P},p\leq n}\left(p\N\right)^{C}\right)\\
 & =\lim_{n\to\infty}\prod_{p\in\mathcal{P},p\leq n}\left(1-\mathbb{P}_{s}\left(p\N\right)\right)\\
 & =\lim_{n\to\infty}\prod_{p\in\mathcal{P},p\leq n}\left(1-p^{-s}\right)\\
 & =\prod_{p\in\mathcal{P}}\left(1-p^{-s}\right)
\end{align*}

\end_inset

where the second equality is due to the fact that 
\begin_inset Formula $1$
\end_inset

 is neither prime nor a product of primes, the third due to the continuity
 of measures (see Propositions 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:measureProperties"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:equivalenceContinuityMeasures"
plural "false"
caps "false"
noprefix "false"

\end_inset

), and the fourth due the fact that 
\begin_inset Formula $\mathbb{P}_{s}\left(\N\right)=1.$
\end_inset


\end_layout

\begin_layout Standard
We are finally ready to present the second Borel-Cantelli lemma, which we
 promised back in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:measurableFunctions"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 The idea here is that if you an infinite sequence of independent events,
 like coin-tosses where the outcomes can either be head or tails, the probabilit
y that you will only see a finite number of heds is intuitively zero.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:secondBorelCantelli"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Second Borel-Cantelli lemma
\end_layout

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $\left\{ A_{i}\right\} _{i\in\N}\in\mathcal{F}$
\end_inset

 be mutually independent events.
 If
\begin_inset Formula 
\[
\sum_{i=1}^{\infty}\mathbb{P}\left(A_{i}\right)=\infty
\]

\end_inset

then 
\begin_inset Formula 
\[
\mathbb{P}\left(\limsup_{i\to\infty}A_{i}\right)=1.
\]

\end_inset


\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\left(\limsup A_{i}\right)^{C}\right) & =\mathbb{P}\left(\left(\bigcap_{n\in\N}\bigcup_{i\geq n}A_{i}\right)^{C}\right)\\
 & =\mathbb{P}\left(\bigcup_{n\in\N}\bigcap_{i\geq n}A_{i}^{C}\right)\\
 & =\lim_{n\to\infty}\mathbb{P}\left(\bigcap_{i\geq n}A_{i}^{C}\right)\\
 & =\lim_{n\to\infty}\lim_{m\to\infty}\mathbb{P}\left(\bigcap_{m\geq i\geq n}A_{i}^{C}\right)\\
 & =\lim_{n\to\infty}\lim_{m\to\infty}\prod_{m\geq i\geq n}\left(1-\mathbb{P}\left(A_{i}\right)\right)\\
 & =\lim_{n\to\infty}\lim_{m\to\infty}\exp\left(\sum_{m\geq i\geq n}\log\left(1-\mathbb{P}\left(A_{i}\right)\right)\right)\\
 & \leq\lim_{n\to\infty}\lim_{m\to\infty}\exp\left(-\sum_{m\geq i\geq n}\mathbb{P}\left(A_{i}\right)\right)\\
 & =\lim_{n\to\infty}\exp\left(-\sum_{i\geq n}\mathbb{P}\left(A_{i}\right)\right)\\
 & =0
\end{align*}

\end_inset

where in the second equality we have used DeMorgan's laws, the third and
 fourth follow from the continuity of measures, the fifth by independence
 and the fact that 
\begin_inset Formula $\mathbb{P}\left(\Omega\right)=1$
\end_inset

, and the inequality by the fact that 
\begin_inset Formula $\log\left(1-x\right)\leq-x$
\end_inset

 for 
\begin_inset Formula $x\in\left[0,1\right).$
\end_inset


\begin_inset Foot
status open

\begin_layout Plain Layout
This can be verified by noting that the function 
\begin_inset Formula $g\left(x\right)=\log\left(1-x\right)+x$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 at 
\begin_inset Formula $x=0$
\end_inset

 and has derivative 
\begin_inset Formula $g^{\prime}\left(x\right)=1-\frac{1}{1-x}=\frac{-x}{1-x}<0$
\end_inset

 for 
\begin_inset Formula $x\in\left(0,1\right).$
\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Note that we can't dispense with the independence assumption on this version
 of the Borel Cantelli lemma, since for identical events 
\begin_inset Formula $A_{i}$
\end_inset

, 
\begin_inset Formula $\limsup A_{i}=A_{1}$
\end_inset

 and so if 
\begin_inset Formula $\mathbb{P}\left(A_{1}\right)<1$
\end_inset

 then 
\begin_inset Formula $\mathbb{P}\left(\limsup A_{i}\right)<1$
\end_inset

 even though 
\begin_inset Formula $\sum\mathbb{P}\left(A_{i}\right)=\infty$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{Differences between mutual and pariwise independence}
\end_layout

\end_inset


\end_layout

\begin_layout Section
Independent 
\begin_inset Formula $\sigma-$
\end_inset

algebras
\end_layout

\begin_layout Standard
The idea of independence of events can be extended to the idea of independence
 of structures of events.
 For a given probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

, we say that a collection of events 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in I}$
\end_inset

 – where 
\begin_inset Formula $I$
\end_inset

 is an arbitrary index set and each 
\begin_inset Formula $\F_{i}\subset\F$
\end_inset

 – is mutually independent if for any finite 
\begin_inset Formula $J\subset I$
\end_inset

 and 
\begin_inset Formula $F_{j}\in\F_{j}$
\end_inset


\begin_inset Formula 
\[
\mathbb{P}\left(\bigcap_{j\in J}F_{j}\right)=\prod_{j\in J}\mathbb{P}\left(F_{j}\right).
\]

\end_inset

Usually, the structures we consider are 
\begin_inset Formula $\sigma-$
\end_inset

algebras, since those are the most important types of collections of events
 in probability theory.
 Immediately, our 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[cor:piLambdaGeneratingClassArg]{$
\backslash
pi-
\backslash
lambda$ theorem}
\end_layout

\end_inset

 gives us some useful tools that allows us to use independence on generating
 classes to prove independence on the 
\begin_inset Formula $\sigma-$
\end_inset

algebras generated by them.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:indepSigmaAlgebras"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 If a collection of 
\begin_inset Formula $\pi-$
\end_inset

systems 
\begin_inset Formula $\left\{ \mathcal{E}_{i}\right\} _{i\in I}\subset\F$
\end_inset

 are independent, then 
\begin_inset Formula $\left\{ \sigma\left(\mathcal{E}_{i}\right)\right\} _{i\in I}$
\end_inset

 are independent.
\end_layout

\begin_layout Proof
Pick some 
\begin_inset Formula $J\subset I$
\end_inset

 such that 
\begin_inset Formula $\lvert J\rvert=n$
\end_inset

.
 Without loss of generality, we can assume that 
\begin_inset Formula $J=\left\{ 1,2,\ldots,n\right\} .$
\end_inset

 Define
\begin_inset Formula 
\[
\mathcal{D}_{1}:=\left\{ F_{1}\in\sigma\left(\mathcal{E}_{1}\right)\mid\mathbb{P}\left(F_{1}\cap E_{2}\cap\ldots\cap E_{n}\right)=\mathbb{P}\left(F_{1}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)\forall E_{i}\in\mathcal{E}_{i},2\leq i\leq n\right\} 
\]

\end_inset

and note that we can show that 
\begin_inset Formula $\mathcal{D}_{1}$
\end_inset

 is a 
\begin_inset Formula $\lambda-$
\end_inset

system.
 To see this, first note that 
\begin_inset Formula $\Omega\in\mathcal{D}_{1}$
\end_inset

 since 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\Omega\cap E_{2}\cap\ldots\cap E_{n}\right) & =\mathbb{P}\left(E_{2}\cap\ldots\cap E_{n}\right)\\
 & =\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)\\
 & =\mathbb{P}\left(\Omega\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)
\end{align*}

\end_inset

where in the second equality we use the independence of the generators.
 Next, suppose that 
\begin_inset Formula $F_{1},F_{2}\in\mathcal{D}_{1}$
\end_inset

 such that 
\begin_inset Formula $F_{2}\subseteq F_{1}$
\end_inset

 and observe that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\left(F_{1}\setminus F_{2}\right)\cap E_{2}\cap\ldots\cap E_{n}\right) & =\mathbb{P}\left(F_{1}\cap E_{2}\cap\ldots\cap E_{n}\right)-\mathbb{P}\left(F_{2}\cap E_{2}\cap\ldots\cap E_{n}\right)\\
 & =\mathbb{P}\left(F_{1}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)-\mathbb{P}\left(F_{2}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)\\
 & =\left(\mathbb{P}\left(F_{1}\right)-\mathbb{P}\left(F_{2}\right)\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)\\
 & =\mathbb{P}\left(F_{1}\setminus F_{2}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)
\end{align*}

\end_inset

which shows that 
\begin_inset Formula $F_{1}\setminus F_{2}\in\mathcal{D}_{1}$
\end_inset

.
 Finally, suppose that 
\begin_inset Formula $\left\{ F_{i}\right\} _{i\in\N}\in\mathcal{D}_{1}$
\end_inset

 such that 
\begin_inset Formula $F_{i}\subset F_{i+1}$
\end_inset

 and note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\left(\bigcup_{i\in\N}F_{i}\right)\cap E_{2}\cap\ldots\cap E_{n}\right) & =\lim_{n\to\infty}\mathbb{P}\left(F_{n}\cap E_{2}\cap\ldots\cap E_{n}\right)\\
 & =\lim_{n\to\infty}\mathbb{P}\left(F_{n}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)\\
 & =\mathbb{P}\left(\bigcup_{i\in\N}F_{i}\right)\mathbb{P}\left(E_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)
\end{align*}

\end_inset

which shows that 
\begin_inset Formula $\bigcup_{i\in\N}F_{i}\in\mathcal{D}_{1}$
\end_inset

.
 Thus 
\begin_inset Formula $\mathcal{D}_{1}$
\end_inset

 is a 
\begin_inset Formula $\lambda-$
\end_inset

system containing 
\begin_inset Formula $\mathcal{E}_{1}$
\end_inset

 and so 
\begin_inset Formula $\sigma\left(\mathcal{E}_{1}\right)\subseteq\mathcal{D}_{1}$
\end_inset

.
 Next, we can define 
\begin_inset Formula 
\[
\mathcal{D}_{2}:=\left\{ F_{2}\in\sigma\left(\mathcal{E}_{2}\right)\mid\mathbb{P}\left(F_{1}\cap F_{2}\cap\ldots\cap E_{n}\right)=\mathbb{P}\left(F_{1}\right)\mathbb{P}\left(F_{2}\right)\ldots\mathbb{P}\left(E_{n}\right)F_{1}\in\sigma\left(\mathcal{E}_{1}\right),E_{i}\in\mathcal{E}_{i},3\leq i\leq n\right\} ,
\]

\end_inset

observe that 
\begin_inset Formula $\mathcal{E}_{2}\subseteq\mathcal{D}_{2}$
\end_inset

 by the result on 
\begin_inset Formula $\mathcal{D}_{1}$
\end_inset

 , and show that 
\begin_inset Formula $\mathcal{D}_{2}$
\end_inset

 is a 
\begin_inset Formula $\lambda-$
\end_inset

system and so 
\begin_inset Formula $\sigma\left(\mathcal{E}_{2}\right)\subseteq\mathcal{D}_{2}$
\end_inset

 and so on.
 This completes the argument.
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "cor:clumping"

\end_inset

Let 
\begin_inset Formula $\left\{ \mathcal{F}_{i}\right\} _{i\in I}$
\end_inset

 be a collection of independent 
\begin_inset Formula $\sigma-$
\end_inset

algebras.
 If 
\begin_inset Formula $J,K\subset I$
\end_inset

 are disjoint, then 
\begin_inset Formula 
\[
\sigma\left(\bigcup_{j\in J}\F_{j}\right)\indep\sigma\left(\bigcup_{k\in K}\F_{k}\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\mathcal{E}_{J}$
\end_inset

 be the collection of all finite intersections of sets in 
\begin_inset Formula $\bigcup_{j\in J}\F_{j}$
\end_inset

 and note that 
\begin_inset Formula $\bigcup_{j\in J}\F_{j}\subset\mathcal{E}_{J}$
\end_inset

 for any 
\begin_inset Formula $j\in J$
\end_inset

 since we can take all sets one at a time.
 Thus 
\begin_inset Formula $\sigma\left(\bigcup_{j\in J}\F_{j}\right)\subseteq\sigma\left(\mathcal{E}_{J}\right)$
\end_inset

.
 Conversely, 
\begin_inset Formula $\mathcal{E}_{J}\subseteq\sigma\left(\bigcup_{j\in J}\F_{j}\right)$
\end_inset

 and so 
\begin_inset Formula $\sigma\left(\bigcup_{j\in J}\F_{j}\right)=\sigma\left(\mathcal{E}_{J}\right).$
\end_inset

 Note that 
\begin_inset Formula $\mathcal{E}_{J}$
\end_inset

 and 
\begin_inset Formula $\mathcal{E}_{K}$
\end_inset

 (where 
\begin_inset Formula $\mathcal{E}_{K}$
\end_inset

 is defined analogously) are 
\begin_inset Formula $\pi-$
\end_inset

systems and so if 
\begin_inset Formula $\mathcal{E}_{J}\indep\mathcal{E}_{K}$
\end_inset

 then 
\begin_inset Formula $\sigma\left(\mathcal{E}_{J}\right)\indep\sigma\left(\mathcal{E}_{K}\right)$
\end_inset

 by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:indepSigmaAlgebras"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Now for any 
\begin_inset Formula $E_{J}\in\mathcal{E}_{J}$
\end_inset

 , we can write 
\begin_inset Formula $E_{J}=\bigcap_{j\in J}F_{j}$
\end_inset

 where 
\begin_inset Formula $F_{j}\in\F_{j}$
\end_inset

 (where for some 
\begin_inset Formula $j$
\end_inset

s 
\begin_inset Formula $F_{j}=\Omega$
\end_inset

).
 Similarly 
\begin_inset Formula $E_{K}\in\mathcal{E}_{K}$
\end_inset

 could be written 
\begin_inset Formula $E_{K}=\bigcap_{k\in K}F_{k}$
\end_inset

.
 Therefore,
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(E_{J}\cap E_{K}\right) & =\mathbb{P}\left(\bigcap_{j\in J}F_{j}\cap\bigcap_{k\in K}F_{k}\right)\\
 & =\mathbb{P}\left(\bigcap_{j\in J}F_{j}\right)\mathbb{P}\left(\bigcap_{k\in K}F_{k}\right)
\end{align*}

\end_inset

where we have used the independence of 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in I}.$
\end_inset


\end_layout

\begin_layout Standard
These results yield as our first 
\emph on
zero-one law 
\emph default
which is a result that characterizes some type of 
\begin_inset Formula $\sigma-$
\end_inset

algebra that only contain events iwth probability zero or one.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:tailSigmaAlgebra"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and suppose 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in\N}\subset\F$
\end_inset

 is a collection of sub 
\begin_inset Formula $\sigma-$
\end_inset

algebras on this space.
 Suppose further that 
\begin_inset Formula $\F=\sigma\left(\bigcup_{i\in I}\F_{i}\right)$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{n}:=\sigma\left(\bigcup_{i\geq n}\F_{i}\right)$
\end_inset

 and so 
\begin_inset Formula $\mathcal{H}_{n+1}\subseteq\mathcal{H}_{n}$
\end_inset

.
 The 
\emph on
tail 
\begin_inset Formula $\sigma-$
\end_inset

algebra 
\emph default
with respect to 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in\N}$
\end_inset

 is given
\begin_inset Formula 
\[
\mathcal{H}_{\infty}=\bigcap_{n\in\N}\mathcal{H}_{n}.
\]

\end_inset


\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:kolmogorovZeroOne"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Kolmogorov's Zero-One Law
\end_layout

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and suppose 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in\N}\subset\F$
\end_inset

 is a collection of mutually independent sub 
\begin_inset Formula $\sigma-$
\end_inset

algebras on this space.
 Then the tail 
\begin_inset Formula $\sigma-$
\end_inset

algebra 
\begin_inset Formula $\mathcal{H}_{\infty}$
\end_inset

 is trivial in that for any 
\begin_inset Formula $A\in\mathcal{H}_{\infty}$
\end_inset


\begin_inset Formula 
\[
\mathbb{P}\left(A\right)\in\left\{ 0,1\right\} .
\]

\end_inset


\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula $\F_{1},\ldots,\F_{n-1}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{n}$
\end_inset

 are mutually independent by an inductive extension of Corollary 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:clumping"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Of course, since 
\begin_inset Formula $\mathcal{H}_{\infty}\subseteq\mathcal{H}_{n}$
\end_inset

 so 
\begin_inset Formula $\F_{1},\ldots,\F_{n}$
\end_inset

 and 
\begin_inset Formula $\mathcal{H}_{\infty}$
\end_inset

 are all mutually independent.
 Of course, since 
\begin_inset Formula $n$
\end_inset

 is arbitrary, we have that 
\begin_inset Formula $\mathcal{H}_{\infty}$
\end_inset

 and 
\begin_inset Formula $\left\{ \F_{i}\right\} _{i\in\N}$
\end_inset

are all mutually independent.
 Again, applying Corollary 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:clumping"
plural "false"
caps "false"
noprefix "false"

\end_inset

, we have that 
\begin_inset Formula $\mathcal{H}_{\infty}\indep\sigma\left(\bigcup_{i\in\N}\F_{i}\right).$
\end_inset

Note that since 
\begin_inset Formula $\mathcal{H}_{\infty}\subset\F=\sigma\left(\bigcup_{i\in\N}\F_{i}\right)$
\end_inset

 we have that 
\begin_inset Formula $\mathcal{H}_{\infty}\indep\mathcal{H}_{\infty}$
\end_inset

and so for any 
\begin_inset Formula $A\in\mathcal{H}_{\infty}$
\end_inset


\begin_inset Formula 
\[
\mathbb{P}\left(A\right)=\mathbb{P}\left(A\right)^{2}\implies\mathbb{P}\left(A\right)\in\left\{ 0,1\right\} .
\]

\end_inset


\end_layout

\begin_layout Section
Random variables
\end_layout

\begin_layout Subsection
General description and terminology
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:randomVariable"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space.
 A 
\emph on
random variable 
\emph default
is a real-valued Borel-measurable map 
\begin_inset Formula $X:\left(\Omega,\F\right)\to\left(\R,\borel\left(\R\right)\right)$
\end_inset

.
 A 
\emph on
random vector 
\emph default
is a measurable map 
\begin_inset Formula $X:\left(\Omega,\F\right)\to\left(\R^{n},\borel\left(\R^{n}\right)\right)$
\end_inset

.
 A 
\emph on
random element 
\emph default
is a measurable map 
\begin_inset Formula $X:\left(\Omega,\F\right)\to\left(S,\mathcal{B}\right)$
\end_inset

 where 
\begin_inset Formula $\left(S,\mathcal{B}\right)$
\end_inset

 is a Polish space with its Borel 
\begin_inset Formula $\sigma-$
\end_inset

algebra.
\end_layout

\begin_layout Standard
Our definitions are increasingly general in that random variables, are random
 vectors, which in turn are random elements.
 Much of our language about measurable functions has analogues in probability.
 For instance, the image measure 
\begin_inset Formula $X\mathbb{P}$
\end_inset

 (which we shall denote as 
\begin_inset Formula $\mathbb{P}_{X}$
\end_inset

 from now on) of 
\begin_inset Formula $X$
\end_inset

 under 
\begin_inset Formula $\mathbb{P}$
\end_inset

 is called the 
\emph on
distribution 
\emph default
of 
\begin_inset Formula $X$
\end_inset

.
 The Radon-Nikodym derivative of this distribution with respect to the Lebesgue
 measure (if it exists) is called the 
\emph on
density 
\emph default
of 
\begin_inset Formula $X$
\end_inset

, which is always non-negative (like all RN-derivatives) and integrates
 to 
\begin_inset Formula $1$
\end_inset

.
 The Stieljes function 
\begin_inset Formula $F_{X}\left(x\right):=\mathbb{P}_{X}\left(\left(-\infty,x\right]\right)$
\end_inset

 is called the 
\emph on
cumulative distribution function (CDF) 
\emph default
of 
\begin_inset Formula $X$
\end_inset

.
 Theorem 
\begin_inset CommandInset ref
LatexCommand ref
reference "thm:stieljesMeasure"
plural "false"
caps "false"
noprefix "false"

\end_inset

 tells us that CDFs completely characterize the distribution of a random
 variable 
\begin_inset Formula $X$
\end_inset

 and so random variables with the same CDF are called 
\emph on
identically distributted.
 
\emph default
Moreover, Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:absoluteContinuityStieljesFunctions"
plural "false"
caps "false"
noprefix "false"

\end_inset

 tells us that the absolute continuity of CDFs (as functions on the real
 line) is equivalent to the absolute continuity of the distribution with
 respect to the Lebesgue measure.
 Of course, not all random variables have absolutely continuous CDFs.
 The canonical pathological example of a random variable which has a continuous
 but not absolutely continuous CDF is the Cantor random variable, whose
 CDF is the 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[def:cantorFunction]{Cantor function}
\end_layout

\end_inset

.
 More importantly, many random variables have countable supports
\begin_inset Foot
status open

\begin_layout Plain Layout
This is again a shorthand! What we mean here is that the CDF has a countable
 support as a real valued function on 
\begin_inset Formula $\R$
\end_inset

.
\end_layout

\end_inset

 and can be thought of as 
\emph on
discrete.
 
\emph default
A reasonably comprehensive accounting of various distributions that we can
 find in the wild can be found in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:probabilityDistributions"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
The CDF has two additional properties that we did not see for Stieljes functions
 in general.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:cdfLimits"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X:\Omega\to\R$
\end_inset

 be a random variable.
 Then its cumulative distribution function 
\begin_inset Formula $F_{X}$
\end_inset

 has the property that 
\begin_inset Formula 
\[
\lim_{x\to\infty}F_{X}\left(x\right)=1
\]

\end_inset

and 
\begin_inset Formula 
\[
\lim_{x\to-\infty}F_{X}\left(x\right)=0.
\]

\end_inset


\end_layout

\begin_layout Proof
Note that the first limit is equivalent to
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{P}_{X}\left(\left(-\infty,n\right]\right) & =\mathbb{P}_{X}\left(\bigcup_{n\in\N}\left(-\infty,n\right]\right)\\
 & =\mathbb{P}_{X}\left(\left(-\infty,\infty\right)\right)\\
 & =1.
\end{align*}

\end_inset

where we used the upper continuity of measures.
 Similarly, the other limit can be written as 
\begin_inset Formula 
\begin{align*}
\lim_{n\to\infty}\mathbb{P}_{X}\left(\left(-\infty,-n\right]\right) & =\mathbb{P}_{X}\left(\bigcap_{n\in\N}\left(-\infty,-n\right]\right)\\
 & =\mathbb{P}_{X}\left(\emptyset\right)\\
 & =0.
\end{align*}

\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:floorFuncCDF"

\end_inset

Let 
\begin_inset Formula $n$
\end_inset

 be a positive integer and suppose that 
\begin_inset Formula 
\[
F\left(x\right)=\frac{\lfloor x\rfloor}{n}\indicate\left\{ 0\leq x\leq n\right\} +\indicate\left\{ x>n\right\} 
\]

\end_inset

 and observe that 
\begin_inset Formula $F$
\end_inset

 is clearly non-decreasing, it is right continuous as the floor function
 is right continuous.
 The limiting behavior is obvious.
 To construct the probability distribution that generates this CDF, one
 can define a random variable 
\begin_inset Formula $X$
\end_inset

 such that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(X=x\right) & =F\left(x\right)-F\left(x-1\right)\\
 & =\frac{1}{n}
\end{align*}

\end_inset

which is the 
\emph on
discrete uniform distribution
\emph default
 over 
\begin_inset Formula $\left\{ 1,2,\ldots,n\right\} $
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:geometricDistOneHalf"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X$
\end_inset

 be a random variable with distribution characterized by
\begin_inset Formula 
\[
\mathbb{P}_{X}\left(\left\{ x\right\} \right)=\left(\frac{1}{2}\right)^{x}\indicate\left\{ x\in\N\right\} .
\]

\end_inset

Since 
\begin_inset Formula 
\[
\mathbb{P}_{X}\left(\N\right)=\sum_{i=1}^{\infty}\frac{1}{2^{i}}=1,
\]

\end_inset

 for this to be a valid distribution, it must be that 
\begin_inset Formula $\mathbb{P}_{X}\left(\R\setminus\N\right)=0.$
\end_inset

 What is the CDF of such a distribution? Well, we know that 
\begin_inset Formula 
\begin{align*}
F_{X}\left(x\right) & =\mathbb{P}_{X}\left(\left(-\infty,x\right]\right)\\
 & =\mathbb{P}_{X}\left(\left(-\infty,x\right]\cap\N\right)\\
 & =\sum_{i=1}^{\lfloor x\rfloor}\frac{1}{2^{i}}\\
 & =1-\frac{1}{2^{\lfloor x\rfloor}}.
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The convex combination of CDFs remains a CDF , which gives rise to mixture
 distributions.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:convexCombinationDistribution"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X,Y$
\end_inset

 be random variables with CDFs 
\begin_inset Formula $F_{X}$
\end_inset

 and 
\begin_inset Formula $F_{Y}$
\end_inset

.
 For any 
\begin_inset Formula $\lambda\in\left[0,1\right]$
\end_inset

 , the function 
\begin_inset Formula $F\left(x\right):=\lambda F_{X}\left(x\right)+\left(1-\lambda\right)F_{Y}\left(x\right)$
\end_inset

 satisfies all the properties of CDF.
\end_layout

\begin_layout Proof
Note that convex combinations of increasing functions is increasing and
 the convex combinations of right continuous functions is right continuous.
 The limiting properties also follow easily since limits behave linearly.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2023psb3"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2023 PSB 3
\end_layout

\end_inset

Do there exist CDFs on 
\begin_inset Formula $\R$
\end_inset

 such that 
\begin_inset Formula $F\left(x\right)=F\left(x^{n}\right)$
\end_inset

 where 
\begin_inset Formula $n>1$
\end_inset

? First, note that if 
\begin_inset Formula $n$
\end_inset

is even, then for any 
\begin_inset Formula $x<0$
\end_inset

 
\begin_inset Formula $F\left(x\right)=F\left(x^{n}\right)$
\end_inset

 which implies that 
\begin_inset Formula 
\begin{align*}
0 & =\lim_{x\to-\infty}F\left(x\right)\\
 & =\lim_{x\to-\infty}F\left(x^{n}\right)\\
 & =\lim_{x\to\infty}F\left(x^{n}\right)\\
 & =1
\end{align*}

\end_inset

which is a contradiction and so no such distribution exists.
 If 
\begin_inset Formula $n$
\end_inset

 is odd then, we have that for any 
\begin_inset Formula $x,y>1$
\end_inset

, we 
\begin_inset Formula $F\left(x\right)=F\left(y\right)$
\end_inset

 since if 
\begin_inset Formula $x<y$
\end_inset

 there exists some 
\begin_inset Formula $k\in\N$
\end_inset

 such 
\begin_inset Formula $x^{n^{k}}>y$
\end_inset

 and so the non-decreasing nature of 
\begin_inset Formula $F$
\end_inset

 yields the result.
 Of course, since 
\begin_inset Formula $\lim_{x\to\infty}F\left(x\right)=1$
\end_inset

, we must have that 
\begin_inset Formula $F\left(x\right)=1$
\end_inset

 for every 
\begin_inset Formula $x>1$
\end_inset

.
 A similar result shows that 
\begin_inset Formula $F\left(x\right)=F\left(y\right)=0$
\end_inset

 for 
\begin_inset Formula $x<-1$
\end_inset

.
 For the intermediate values of 
\begin_inset Formula $x$
\end_inset

, we know that for any 
\begin_inset Formula $x_{1},x_{2}\in\left[-1,0\right)$
\end_inset

 and 
\begin_inset Formula $y_{1},y_{2}\in\left(0,1\right]$
\end_inset

 that 
\begin_inset Formula $0\leq F\left(x_{1}\right)=F\left(x_{2}\right)\leq F\left(0\right)\leq F\left(y_{1}\right)=F\left(y_{2}\right)\leq1$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2008samplepsb6"

\end_inset

Let 
\begin_inset Formula $F$
\end_inset

 and 
\begin_inset Formula $G$
\end_inset

 be (one dimensional) distribution functions.
 Decide which of the following are distribution functions.
 (a) 
\begin_inset Formula $F^{2}$
\end_inset

, (b) 
\begin_inset Formula $H$
\end_inset

 where 
\begin_inset Formula $H(t)=\max\{F(t),G(t)\}$
\end_inset

.
\end_layout

\begin_layout Example
Justify your answer.
\end_layout

\begin_layout Standard
The integral of a random variable is called an 
\emph on
expectation 
\emph default
(provided it exists).
 That is, 
\begin_inset Formula $\lebInt{\mathbb{P}}X$
\end_inset

 is the expectation of 
\begin_inset Formula $X$
\end_inset

.
 In the probability literature, this is often denoted 
\begin_inset Formula $\mathbb{E}\left[X\right]$
\end_inset

.
 Since random variables are defined on measures spaces with unit measure,
 the integral captures the average value of the function 
\begin_inset Formula $X$
\end_inset

.
 If 
\begin_inset Formula $X\in\mathcal{L}^{p}$
\end_inset

 for 
\begin_inset Formula $p>1$
\end_inset

 then the random variable is said to have finite 
\begin_inset Formula $p$
\end_inset

th moment.
 Of course, by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:nestingLpSpace"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we know that if a random variable has a finite 
\begin_inset Formula $p$
\end_inset

th moment, it has a finite 
\begin_inset Formula $q$
\end_inset

th moment for 
\begin_inset Formula $1\leq q\leq p$
\end_inset

.
 Some moments have special names.
 So, for instance, for the centered random variable 
\begin_inset Formula $Y:=X-\mathbb{E}\left[X\right]$
\end_inset

, the second moment 
\begin_inset Formula $\text{\Var\left[X\right]:=}\mathbb{E}\left[Y^{2}\right]=\E\left[X^{2}\right]-\left(\E\left[X\right]\right)^{2}$
\end_inset

 is called the 
\emph on
variance
\emph default
 of 
\begin_inset Formula $X$
\end_inset

.
 It is often denoted as 
\begin_inset Formula $\sigma^{2}$
\end_inset

 and it captures the degree to which a random variable deviates from its
 mean value.
 The third 
\emph on
standardized 
\emph default
moment 
\begin_inset Formula $\mathbb{E}\left[\left(\frac{Y}{\sigma}\right)^{3}\right]$
\end_inset

 is called the 
\emph on
skewness; 
\emph default
it captures the degree to which a random variables distribution is asymmetric.
 Here 
\begin_inset Formula $\sigma$
\end_inset

 is the square root of the variance, and is referred to as the 
\emph on
standard deviation 
\emph default
of 
\begin_inset Formula $X$
\end_inset

.
 The fourth standardized moment 
\begin_inset Formula $\E\left[\left(\frac{Y}{\sigma}\right)^{4}\right]$
\end_inset

 is called thee kurtosis.
 Of course, random variables need not even by 
\begin_inset Formula $\mathcal{L}^{1}$
\end_inset

, as the following two examples illustrate.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:cauchyDistribution"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probabiltiy space and let 
\begin_inset Formula $X:\Omega\to\R$
\end_inset

 be a random variable whose distribution is absolutely continuous with respect
 to the Lebesgue measure with density 
\begin_inset Formula $f_{X}\left(x\right)=\frac{1}{\pi\left(1+x^{2}\right)}$
\end_inset

.
 Note that this is a valid density since 
\begin_inset Formula 
\begin{align*}
\lebInt{\lambda}{\frac{1}{\pi\left(1+x^{2}\right)}} & =\int_{-\infty}^{\infty}\frac{1}{\pi\left(1+x^{2}\right)}\\
 & =\int_{-\infty}^{0}\frac{1}{\pi\left(1+x^{2}\right)}+\int_{0}^{\infty}\frac{1}{\pi\left(1+x^{2}\right)}\\
 & =\frac{2}{\pi}\int_{0}^{\infty}\frac{1}{\left(1+x^{2}\right)}\\
 & =\frac{2}{\pi}\lim_{b\to\infty}\tan^{-1}\left(b\right)-\tan^{-1}\left(0\right)\\
 & =\frac{2}{\pi}\frac{\pi}{2}\\
 & =1
\end{align*}

\end_inset

where in the third equality we used the the symmetry of the density (and
 hence distribution)
\begin_inset Foot
status open

\begin_layout Plain Layout
The symmetry of the distribution of a random variable is an important property
 that characterizes many of the common probability distributions we hear
 about in probability and statistics.
 For instance, the normal distribution, and the uniform distribution, are
 both symmetric distributions.
 A probability distribution of a random variable 
\begin_inset Formula $X$
\end_inset

 is said to be symmetric about 
\begin_inset Formula $0$
\end_inset

 if for any 
\begin_inset Formula $x\in\R$
\end_inset


\begin_inset Formula $:F_{X}(x)=1-F_{X}\left(-x\right).$
\end_inset


\end_layout

\end_inset

 and in the fourth the fact that the derivative of 
\begin_inset Formula $\tan^{-1}\left(x\right)$
\end_inset

 is 
\begin_inset Formula $\frac{1}{1+x^{2}}$
\end_inset

 and the fundamental theorem of calculus.
 To see that the first moment doesn't exist, observe that 
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left[X\right] & =\E\left[X^{+}\right]-\E\left[X^{-}\right]\\
 & =\int_{0}^{\infty}\frac{x}{\pi\left(1+x^{2}\right)}dx-\int_{0}^{\infty}\frac{x}{\pi\left(1+x^{2}\right)}dx\\
\end{align*}

\end_inset

where in the second equality we have used Corollaries 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:changeOfVariables"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:densityIntegral"
plural "false"
caps "false"
noprefix "false"

\end_inset

 along with the Radon-Nikodym theorem.
 Thus the expectation is zero if the integral of the parts is finite; otherwise
 it is not defined.
 To this end, note that 
\begin_inset Formula 
\begin{align*}
\int_{0}^{\infty}\frac{x}{\pi\left(1+x^{2}\right)}dx & =\frac{1}{2\pi}\int_{1}^{\infty}\frac{1}{u}du\\
 & =\frac{1}{2\pi}\left[\lim_{b\to\infty}\log\left(b\right)-\log\left(1\right)\right]\\
 & =\infty
\end{align*}

\end_inset

which shows that 
\begin_inset Formula $\E\left[X\right]$
\end_inset

 is not defined.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2008samplepsb4"

\end_inset

Consider the unit interval 
\begin_inset Formula $(0,1)$
\end_inset

 that is divided into two sub-intervals by picking a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[subsec:uniformDistribution]{point at random}
\end_layout

\end_inset

 from inside the interval.
 Denoting by 
\begin_inset Formula $Y$
\end_inset

 and 
\begin_inset Formula $Z$
\end_inset

 the lengths of the longer and the shorter sub-intervals respectively, we
 can show that 
\begin_inset Formula $Y/Z$
\end_inset

 does not have finite expectation.
 Indeed, letting 
\begin_inset Formula $X$
\end_inset

 be the uniformly distributed random variable in 
\begin_inset Formula $\left(0,1\right)$
\end_inset

, we have that 
\begin_inset Formula 
\begin{align*}
\E\left[\frac{Y}{Z}\right] & =\E\left[\frac{1-X}{X}\indicate\left\{ 0\leq X\leq0.5\right\} +\frac{X}{1-X}\indicate\left\{ 0.5\leq X\leq1\right\} \right]\\
 & =\E\left[\frac{1-X}{X}\indicate\left\{ 0\leq X\leq0.5\right\} \right]+\E\left[\frac{X}{1-X}\indicate\left\{ 0.5\leq X\leq1\right\} \right]\\
 & =\int_{0}^{0.5}\frac{1-x}{x}dx+\int_{0.5}^{1}\frac{x}{1-x}dx\\
\end{align*}

\end_inset

where neither integral is finite.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
The following is an example of a discrete probability distribution where
 the expectation does exist.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2007samplepsb6"

\end_inset

18 boys and 2 girls are made to stand in a line in a random order.
 Let 
\begin_inset Formula $X$
\end_inset

 be the number of boys standing in between the girls.
 Whati s 
\begin_inset Formula $P(X=k)$
\end_inset

 and 
\begin_inset Formula $\E(X)$
\end_inset

? Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Combinatorics"
plural "false"
caps "false"
noprefix "false"

\end_inset

 will be useful here.
 Note that if there are 
\begin_inset Formula $b$
\end_inset

 boys and 2 girls, there are 
\begin_inset Formula $\left(b+2\right)!$
\end_inset

 ways to arrange them and 
\begin_inset Formula $b+2-k-1$
\end_inset

 ways to sandwich 
\begin_inset Formula $k$
\end_inset

 boys between two girls, with 
\begin_inset Formula $b!$
\end_inset

 ways to arrange the boys and 
\begin_inset Formula $g!$
\end_inset

 ways to arrange the girls.
 Therefore
\begin_inset Formula 
\begin{align*}
\P\left(X=k\right) & =\frac{\left(b+2-k-1\right)b!2!}{\left(b+2\right)!}\\
 & =\frac{b+2-k-1}{\left(b+2\right)!}
\end{align*}

\end_inset

 To find the expectation, note that 
\begin_inset Formula 
\begin{align*}
\E\left[X\right] & =\frac{2}{\left(b+2\right)\left(b+1\right)}\sum_{k=0}^{b}k\left(b+2-k-1\right)\\
 & =\frac{2}{\left(b+2\right)\left(b+1\right)}\sum_{k=1}^{b}k\left(b+1-k\right)\\
 & =\frac{2}{\left(b+2\right)\left(b+1\right)}\left(\begin{array}{c}
b+2\\
3
\end{array}\right)\\
 & =\frac{2}{\left(b+2\right)\left(b+1\right)}\frac{b\left(b+1\right)\left(b+2\right)}{6}\\
 & =\frac{b}{3}
\end{align*}

\end_inset

where in the third equality we used Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:mdmActivity103"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
We can characterize 
\emph on
joint 
\emph default
moments of multiple random variables just as easily.
 For instance, the 
\emph on
covariance 
\emph default
of two random variables 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 on the same probability space is simply their centered inner product 
\begin_inset Formula $\Cov\left[X,Y\right]:=\mathbb{E}\left[\left(X-\mathbb{E}\left[X\right]\right)\left(Y-\mathbb{E}\left[Y\right]\right)\right]=\E\left[XY\right]-\E\left[X\right]\E\left[Y\right]$
\end_inset

.
 Notice that this is a generalization of the variance which is essentially
 the covariance of a random variable with itself.
 The bilinearity of inner products lends itself very nicely to covariances.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2015psb5ptA"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be 
\begin_inset Formula $\mathcal{L}^{2}$
\end_inset

 random variables such that 
\begin_inset Formula $\Var\left[X+Y\right]=3,$
\end_inset

 and 
\begin_inset Formula $\Var\left[X-Y\right]=1$
\end_inset

.
 What is 
\begin_inset Formula $\Cov\left[X,Y\right]$
\end_inset

? We use the bilinearity of covariances here.
 Note that 
\begin_inset Formula $\Var\left[X+Y\right]=\Var\left[X\right]+\Var\left[Y\right]+2\Cov\left[X,Y\right]$
\end_inset

 and 
\begin_inset Formula $\Var\left[X-Y\right]=\Var\left[X\right]+\Var\left[Y\right]-2\Cov\left[X,Y\right]$
\end_inset

.
 Subtracting the two equations yields 
\begin_inset Formula $\Cov\left[X,Y\right]=\frac{1}{2}$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2006samplepsb6"

\end_inset

Let 
\begin_inset Formula $Y_{1},Y_{2},Y_{3}$
\end_inset

 be i.i.d.
 continuous random variables.
 For 
\begin_inset Formula $i=1,2$
\end_inset

, define 
\begin_inset Formula $U_{i}$
\end_inset

 as 
\begin_inset Formula 
\[
U_{i}=\begin{cases}
1 & \text{ if }Y_{i+1}>Y_{i},\\
0 & \text{ otherwise }
\end{cases}
\]

\end_inset


\end_layout

\begin_layout Example
What is the mean and variance of 
\begin_inset Formula $U_{1}+U_{2}$
\end_inset

? The key here is that the random variables are continuous and so 
\begin_inset Formula $\P\left(Y_{i}=Y_{i+1}\right)=0$
\end_inset

.
 Since then 
\begin_inset Formula $\P\left(Y_{i}>Y_{i+1}\right)=\P\left(Y_{i}<Y_{i+1}\right)=\frac{1}{2}$
\end_inset

, we have that 
\begin_inset Formula $\E\left[U_{1}+U_{2}\right]=\P\left(Y_{2}>Y_{1}\right)+\P\left(Y_{3}>Y_{2}\right)=1$
\end_inset

.
 For the variance, note that 
\begin_inset Formula 
\begin{align*}
\Var\left[U_{1}+U_{2}\right] & =\Var\left[U_{1}\right]+\Var\left[U_{2}\right]+2\Cov\left[U_{1},U_{2}\right]\\
 & =2\left(\E\left[U_{1}^{2}\right]-\E\left[U_{1}\right]^{2}\right)+2\left(\E\left[U_{1}U_{2}\right]-\E\left[U_{1}\right]\E\left[U_{2}\right]\right)\\
 & =2\left(\frac{1}{2}-\frac{1}{4}\right)+2\left(\frac{1}{6}-\frac{1}{4}\right)\\
 & =\frac{1}{2}-\frac{1}{6}\\
 & =\frac{1}{3}.
\end{align*}

\end_inset

where in the second equality we have used the fact that 
\begin_inset Formula $U_{1}$
\end_inset

 and 
\begin_inset Formula $U_{2}$
\end_inset

 are identically distributed and in the third the fact that 
\begin_inset Formula $\P\left(Y_{3}>Y_{2}>Y_{1}\right)=\frac{1}{6}$
\end_inset

 since there are 
\begin_inset Formula $3!$
\end_inset

 ways to arrange those three random variables.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
The 
\emph on
Pearson correlation coefficient 
\emph default
between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, is defined 
\begin_inset Formula 
\[
r_{X,Y}:=\frac{\Cov\left[X,Y\right]}{\sqrt{\Var\left[X\right]\Var\left[Y\right]}}
\]

\end_inset

which captures the degree of linear association between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

.
 This plays a large role in the context of linear regression which we shall
 see in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:linearModels"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2004samplepsb1"

\end_inset

Suppose two teams play a series of games, each producing a winner and a
 loser, until one team has won two more games than the other.
 Let 
\begin_inset Formula $G$
\end_inset

 be the total number of games played.
 Assume each team has a chance of 0.5 to win each game, independent of the
 results of the previous games.
 (a) Find the probability distribution of 
\begin_inset Formula $G$
\end_inset

.
 (b) Find the expected value of 
\begin_inset Formula $G$
\end_inset

.
\end_layout

\begin_layout Solution*
Note that for this series to end the last two games have to be won by the
 same time, with the previous games being won alternatively by one team
 and the other.
 For a series of 
\begin_inset Formula $n$
\end_inset

 games, there are 
\begin_inset Formula $2^{n}$
\end_inset

 total possible outcomes and only two lead to termination, one where team
 1 wins the last two games and the previous ones are won alternatingly and
 the other where team 2 wins the last two games etc.
 Therefore 
\begin_inset Formula $\P\left(G=n\right)=\frac{n}{2^{n-1}}1\indicate\left\{ n\geq2\right\} .$
\end_inset

 Then the expectation is 
\begin_inset Formula 
\begin{align*}
\E\left[G\right] & =\sum_{n=2}^{\infty}\frac{n}{2^{n-1}}
\end{align*}

\end_inset

which is arithmo-geometric series that can be shown to converge using a
 ratio test.
 We can note that for 
\begin_inset Formula $\lvert x\rvert\leq1$
\end_inset


\begin_inset Formula 
\[
\frac{1}{1-x}=\sum_{n=0}^{\infty}x^{n}
\]

\end_inset

and so by the fact that the power series converges uniformly, 
\begin_inset Formula 
\[
\frac{1}{\left(1-x\right)^{2}}=\sum_{n=1}^{\infty}nx^{n-1}
\]

\end_inset

where we have interchanged derivatives and limits
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{Add hyperrefs once differentiation section is complete}
\end_layout

\end_inset

.
 Finally, we have 
\begin_inset Formula 
\[
\frac{1}{\left(1-x\right)^{2}}-1=\sum_{n=2}^{\infty}nx^{n-1}.
\]

\end_inset

Letting 
\begin_inset Formula $x=\frac{1}{2}$
\end_inset

, we have that 
\begin_inset Formula 
\[
\E\left[G\right]=4-1=3.
\]

\end_inset


\end_layout

\begin_layout Subsubsection
Quantile functions and coupling
\end_layout

\begin_layout Standard
The expectation of a random variable 
\begin_inset Formula $X$
\end_inset

, if it exists, provides one measure of central tendency for a random variable.
 Other useful measures include the 
\emph on
median, 
\emph default
which is a real number 
\begin_inset Formula $c$
\end_inset

 such that the probability that 
\begin_inset Formula $X$
\end_inset

 less than or equal 
\begin_inset Formula $c$
\end_inset

 is 
\begin_inset Formula $\frac{1}{2}$
\end_inset

.
 This is a useful measure of central tendency when the distribution of 
\begin_inset Formula $X$
\end_inset

 is highly skewed.
 The median may not be unique, as is the case when the random variable 
\begin_inset Formula $X$
\end_inset

 has a discrete distribution.
 More formally, we can define a median
\emph on
 
\emph default
as any real number 
\begin_inset Formula $c\in\left[\sup\left\{ x\in\R\mid F\left(x\right)<\frac{1}{2}\right\} ,\sup\left\{ x\in\R\mid F\left(x\right)\leq\frac{1}{2}\right\} \right]$
\end_inset

 where 
\begin_inset Formula $F$
\end_inset

 is the CDF of 
\begin_inset Formula $X$
\end_inset

.
 In general, the 
\begin_inset Formula $p$
\end_inset

th quantile is any element of the set 
\begin_inset Formula $Q_{F}\left(p\right):=\left[\sup\left\{ x\in\R\mid F\left(x\right)<p\right\} ,\sup\left\{ x\in\R\mid F\left(x\right)\leq p\right\} \right]$
\end_inset

.
 To prevent ambiguity, we often use the lowest value of this interval to
 construct a quantile function.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:quantileFunction"

\end_inset

A quantile function 
\begin_inset Formula $q_{F}$
\end_inset

 for a given CDF 
\begin_inset Formula $F$
\end_inset

 is defined
\begin_inset Formula 
\[
q_{F}\left(p\right):=\inf\left\{ x\in\R\mid F\left(x\right)\geq p\right\} .
\]

\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:quantileProperty"

\end_inset

Let 
\begin_inset Formula $q_{F}$
\end_inset

 be the quantile function associated with a CDF 
\begin_inset Formula $F$
\end_inset

.
 Then 
\begin_inset Formula $q_{F}$
\end_inset

 is the unique function such that 
\begin_inset Formula $F(x)\geq p\Longleftrightarrow q_{F}(p)\leq x$
\end_inset

.
\end_layout

\begin_layout Proof
First we prove that 
\begin_inset Formula $q_{F}$
\end_inset

 satisfies these properties.
 Assume that 
\begin_inset Formula $F\left(x\right)\geq p$
\end_inset

 for some 
\begin_inset Formula $x\in\R$
\end_inset

.
 Then clearly 
\begin_inset Formula $q_{F}\left(p\right)\leq x$
\end_inset

 by the definition of an infimum.
 Conversely, assume that 
\begin_inset Formula $q_{F}\left(p\right)\leq x$
\end_inset

 and observe that since 
\begin_inset Formula $F$
\end_inset

 is non-decreasing, 
\begin_inset Formula $F\left(x\right)\geq p$
\end_inset

.
 Next, suppose that some function 
\begin_inset Formula $\tilde{q}$
\end_inset

 satisfies this equivalence i.e.
 
\begin_inset Formula 
\begin{equation}
F(x)\geq p\Longleftrightarrow\tilde{q}(p)\leq x.\label{eq:assumptionEquivalence}
\end{equation}

\end_inset

Observe that by the right continuity of 
\begin_inset Formula $F$
\end_inset

, 
\begin_inset Formula $F\left(q_{F}\left(p\right)\right)\geq p$
\end_inset

 and so 
\begin_inset Formula $\tilde{q}\left(p\right)\leq q_{F}\left(p\right)$
\end_inset

.
 On the other hand, if there exists some 
\begin_inset Formula $p^{*}\in\left[0,1\right]$
\end_inset

 such that 
\begin_inset Formula $\tilde{q}\left(p^{*}\right)<q_{F}\left(p^{*}\right)$
\end_inset

 then 
\begin_inset Formula $F\left(\tilde{q}\left(p^{*}\right)\right)<p^{*}$
\end_inset

 which by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:assumptionEquivalence"
plural "false"
caps "false"
noprefix "false"

\end_inset

 implies that 
\begin_inset Formula $\tilde{q}\left(p^{*}\right)>\tilde{q}\left(p^{*}\right),$
\end_inset

 a contradiction.
 Therefore,
\begin_inset Formula 
\[
q_{F}\left(p\right)=\tilde{q}\left(p\right)
\]

\end_inset

for all 
\begin_inset Formula $p\in\left[0,1\right]$
\end_inset

.
\end_layout

\begin_layout Standard
Note that the quantile function can also be written as 
\begin_inset Formula $q_{F}\left(p\right)=\sup\left\{ x\in\R\mid F\left(x\right)<p\right\} $
\end_inset

, a fact that can be established by noting that the non-decreasing nature
 of 
\begin_inset Formula $F$
\end_inset

 implies that 
\begin_inset Formula $\sup\left\{ x\in\R\mid F\left(x\right)<p\right\} \leq\inf\left\{ x\in\R\mid F\left(x\right)\geq p\right\} $
\end_inset

.
 If the inequality were strict, then there would be some 
\begin_inset Formula $\sup\left\{ x\in\R\mid F\left(x\right)<p\right\} <c<\inf\left\{ x\in\R\mid F\left(x\right)\geq p\right\} $
\end_inset

 and so 
\begin_inset Formula $F\left(c\right)\not<p$
\end_inset

 and 
\begin_inset Formula $F\left(c\right)\not\geq p$
\end_inset

 which is a contradiction.
\end_layout

\begin_layout Standard
We can use the quantile function to construct a standard probability space
 for random variables to live in.
 To begin, let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be arbitrary and let 
\begin_inset Formula $X$
\end_inset

 be a random variable on the space with CDF 
\begin_inset Formula $F_{X}$
\end_inset

.
 Define an auxiliary random variable on 
\begin_inset Formula $\tilde{X}:\left(\left[0,1\right],\borel\left[0,1\right],\lambda\right)\to\left(\R,\borel\left(\R\right)\right)$
\end_inset

 by 
\begin_inset Formula 
\[
\tilde{X}\left(p\right):=q_{F_{X}}\left(p\right)
\]

\end_inset

 and notice that its CDF 
\begin_inset Formula 
\begin{align*}
F_{\tilde{X}}\left(x\right) & :=\lambda\left(\tilde{X}^{-1}\left[\left(-\infty,x\right]\right]\right)\\
 & =\lambda\left(\left\{ p:q_{F_{X}}\left(p\right)\leq x\right\} \right)\\
 & =\lambda\left(\left\{ p:F_{X}\left(x\right)\geq p\right\} \right)\\
 & =\lambda\left(\left[0,F_{X}\left(x\right)\right]\right)\\
 & =F_{X}\left(x\right).
\end{align*}

\end_inset

Thus we have taken an arbitrary random variable on 
\begin_inset Formula $X$
\end_inset

 on an unspecified probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

 and constructed an auxiliary random variable 
\begin_inset Formula $\tilde{X}$
\end_inset

 on 
\begin_inset Formula $\left(\left[0,1\right],\borel\left[0,1\right],\lambda\right)$
\end_inset

 such that 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $\tilde{X}$
\end_inset

 are identically distributed.
 Since probability is fundamentally concerned with 
\emph on
distributions 
\emph default
rather than random variables as functions themselves, we have found a canonical
 representation for all random variables on the same space 
\begin_inset Formula $\left(\left[0,1\right],\borel\left[0,1\right],\lambda\right)$
\end_inset

.
 The next result provides some evidence that this representation is indeed
 special.
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:coupling"

\end_inset

 Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be random variables, not necessarily on the same probability space.
 A 
\emph on
coupling 
\emph default
of 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

are two new random variables 
\begin_inset Formula $\tilde{X}$
\end_inset

 and 
\begin_inset Formula $\tilde{Y}$
\end_inset

 on a common probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

 such that 
\begin_inset Formula $\tilde{X}$
\end_inset

 has the same distribution as 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $\tilde{Y}$
\end_inset

 has the same distribution as 
\begin_inset Formula $Y$
\end_inset

.
 When we define 
\begin_inset Formula $\tilde{X}\left(p\right)=q_{F_{X}}\left(p\right)$
\end_inset

 and 
\begin_inset Formula $\tilde{Y}\left(p\right)=q_{F_{Y}}\left(p\right)$
\end_inset

 on 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\xout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\left(\left[0,1\right],\borel\left[0,1\right],\lambda\right)$
\end_inset

, then we call 
\begin_inset Formula $\left(\tilde{X},\tilde{Y},\left(\left[0,1\right],\borel\left[0,1\right],\lambda\right)\right)$
\end_inset

 a 
\family default
\series default
\shape default
\size default
\emph on
\bar default
\strikeout default
\xout default
\uuline default
\uwave default
\noun default
\color inherit
quantile coupling
\emph default
.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:quantileCouplingBest"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be random variables, not necessarily on the same probability space.
 Then for any coupling 
\begin_inset Formula $\left(\hat{X},\hat{Y},\probabilityspace\right)$
\end_inset

, we have that 
\begin_inset Formula 
\[
\lambda\left(\lvert\hat{X}-\hat{Y}\rvert\right)\leq\P\left(\lvert\tilde{X}-\tilde{Y}\rvert\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Note that for any 
\begin_inset Formula $s\in\R$
\end_inset


\begin_inset Formula 
\begin{align*}
\P\left(\hat{X}>s,\hat{Y}>s\right) & \leq\min\left\{ \P\left(\hat{X}>s\right),\P\left(\hat{Y}>s\right)\right\} \\
 & =\min\left\{ 1-F_{X}\left(s\right),1-F_{Y}\left(s\right)\right\} \\
 & =1-\max\left\{ F_{X}\left(s\right),F_{Y}\left(s\right)\right\} \\
 & =1-\lambda\left(p:0\leq p\leq\max\left\{ F_{X}\left(s\right),F_{Y}\left(s\right)\right\} \right)\\
 & =\lambda\left(p:\max\left\{ F_{X}\left(s\right),F_{Y}\left(s\right)\right\} <p\leq1\right)\\
 & =\lambda\left(p:F_{X}\left(s\right)<p,F_{Y}\left(s\right)<p\right)\\
 & =\lambda\left(p:q_{F_{X}}\left(p\right)>s,q_{F_{Y}}\left(p\right)>s\right)\\
 & =\lambda\left(p:\tilde{X}\left(p\right)>s,\tilde{Y}\left(p\right)>s\right)
\end{align*}

\end_inset

where in the second to last equality wee have used Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:quantileProperty"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
 Further, by the definition of a coupling
\begin_inset Formula 
\begin{align*}
\P\left(\hat{X}>s\right) & =\lambda\left(\tilde{X}>s\right)\\
\P\left(\hat{Y}>s\right) & =\lambda\left(\tilde{Y}>s\right)
\end{align*}

\end_inset

and so
\begin_inset Formula 
\[
\lebInt{\P}{\indicate\left\{ \hat{X}>s\right\} +\indicate\left\{ \hat{Y}>x\right\} -2\indicate\left\{ \hat{X}>s,\hat{Y}>s\right\} }\geq\lambda\left(\indicate\left\{ \text{\ensuremath{\tilde{X}}}>s\right\} +\indicate\left\{ \tilde{Y}>x\right\} -2\indicate\left\{ \tilde{X}>s,\tilde{Y}>s\right\} \right).
\]

\end_inset

Note that the expressions inside the integrals are indicators of the symmetric
 differences 
\begin_inset Formula $\left\{ \hat{X}>s\right\} \Delta\left\{ \hat{Y}>s\right\} $
\end_inset

 and 
\begin_inset Formula $\left\{ \tilde{X}>s\right\} \Delta\left\{ \tilde{Y}>s\right\} $
\end_inset

 and so we can write the above as 
\begin_inset Formula 
\begin{align}
\P\left(\omega\in\Omega:\hat{X}\left(\omega\right)>s>\hat{Y}\left(\omega\right)\right)+\P\left(\omega\in\Omega:\hat{Y}\left(\omega\right)>s>\hat{X}\left(\omega\right)\right)\nonumber \\
\geq\lambda\left(p\in\left[0,1\right]:\tilde{X}\left(p\right)>s>\tilde{Y}\left(p\right)\right)+\lambda\left(p\in\left[0,1\right]:\tilde{Y}\left(p\right)>s>\tilde{X}\left(p\right)\right)\label{eq:quantileInequality}
\end{align}

\end_inset

Taking an integral with respect to the Lebesgue measure on 
\begin_inset Formula $\R$
\end_inset

 on the left hand side, we hav
\begin_inset Formula 
\begin{align*}
\lambda^{s}\left(\P^{\omega}\left(\omega\in\Omega:\hat{X}\left(\omega\right)>s>\hat{Y}\left(\omega\right)\right)+\P^{\omega}\left(\omega\in\Omega:\hat{Y}\left(\omega\right)>s>\hat{X}\left(\omega\right)\right)\right)\\
=\lambda^{s}\left(\P^{\omega}\left(\indicate\left\{ \hat{X}\left(\omega\right)>s>\hat{Y}\left(\omega\right)\right\} \right)\right) & +\lambda^{s}\left(\P^{\omega}\left(\indicate\left\{ \hat{Y}\left(\omega\right)>s>\hat{X}\left(\omega\right)\right\} \right)\right)\\
=\P^{\omega}\left(\lambda^{s}\left(\indicate\left\{ \hat{X}\left(\omega\right)>s>\hat{Y}\left(\omega\right)\right\} \right)\right) & +\P^{\omega}\left(\lambda^{s}\left(\indicate\left\{ \hat{Y}\left(\omega\right)>s>\hat{X}\left(\omega\right)\right\} \right)\right)\\
=\P^{\omega}\left(\hat{X}-\hat{Y}\right)^{+}+\ \P^{\omega}\left(\hat{Y}-\hat{X}\right)^{+}\quad\\
=\P^{\omega}\left(\lvert\hat{X}-\hat{Y}\rvert\right)\qquad\qquad\qquad\qquad\quad\  & .
\end{align*}

\end_inset

where we have used 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[thm:tonelli]{Tonelli's theorem}
\end_layout

\end_inset

 in the second equality and the fact that 
\begin_inset Formula $f^{-}+f^{+}=\lvert f\rvert$
\end_inset

 in the last.
 A similar argument where we apply 
\begin_inset Formula $\lambda^{s}$
\end_inset

 to the right side of 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:quantileInequality"
plural "false"
caps "false"
noprefix "false"

\end_inset

 shows (by monotonicity of integration) that
\begin_inset Formula 
\[
\P^{\omega}\left(\lvert\hat{X}-\hat{Y}\rvert\right)\geq\lambda\left(\lvert\tilde{X}-\tilde{Y}\rvert\right).
\]

\end_inset


\end_layout

\begin_layout Subsection
Independence of random variables
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:indepRandomVariables"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 Random variables 
\begin_inset Formula $X_{i}:\Omega\to\R$
\end_inset

 where 
\begin_inset Formula $i\in I$
\end_inset

 are independent if 
\begin_inset Formula $\left\{ \sigma\left(X_{i}\right)\right\} _{i\in I}$
\end_inset

 are mutually independent 
\begin_inset Formula $\sigma-$
\end_inset

algebras.
\end_layout

\begin_layout Definition
Note that when 
\begin_inset Formula $I$
\end_inset

 is finite, the existence of finite product measures tells us that we can
 always construct independent random variables with distributions identical
 to 
\begin_inset Formula $\left\{ X_{i}\right\} _{i\in I}$
\end_inset

 .
 For infinite products we use the Kolmogorov extension theorem.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO: Flesh out}
\end_layout

\end_inset

A collection of random variables which are independent and have the same
 distribution are called 
\emph on
independent and identically distributed 
\emph default
or 
\emph on
i.i.d 
\emph default
for short.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:indepFunctionsRandomVariables"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $I$
\end_inset

 be an index set.
 If 
\begin_inset Formula $X_{i}:\Omega\to\R$
\end_inset

 – where 
\begin_inset Formula $i\in I$
\end_inset

 – are independent random variables and 
\begin_inset Formula $f_{i}:\R\to\R$
\end_inset

 are Borel-measuarable maps then the random variables 
\begin_inset Formula $f_{i}\left(X_{i}\right)$
\end_inset

 are mutually independent.
\end_layout

\begin_layout Proof
Note that by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:sigmaAlgebraGeneratedByFunction"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $\sigma\left(f_{i}\left(X_{i}\right)\right)\subseteq\sigma\left(X_{i}\right)$
\end_inset

 and so 
\begin_inset Formula $\sigma\left(f_{i}\left(X_{i}\right)\right)$
\end_inset

 are all mutually independent by definition.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:indepCDFFactors"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be random variables.
 Then 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are independent if and only if 
\begin_inset Formula 
\[
F_{X,Y}\left(x,y\right):=\P\left(X\leq x\cap Y\leq y\right)=\P\left(X\leq x\right)\P\left(Y\leq y\right)=F_{X}\left(x\right)F_{Y}\left(y\right).
\]

\end_inset


\end_layout

\begin_layout Proof
One direction of this is trivial.
 For the non-trivial direction, notice that – by Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:collectionIntervalsMeasurable"
plural "false"
caps "false"
noprefix "false"

\end_inset

 – sets like 
\begin_inset Formula $\left(-\infty,x\right]$
\end_inset

 can be used to generate 
\begin_inset Formula $\borel\left(\R\right).$
\end_inset

 Further, observe that the collection is a 
\begin_inset Formula $\pi-$
\end_inset

system, and so by Corollary 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:generatorPreimage"
plural "false"
caps "false"
noprefix "false"

\end_inset

, 
\begin_inset Formula $\left\{ X^{-1}\left(\left(-\infty,x\right]\right)\right\} _{x\in\R}$
\end_inset

 and 
\begin_inset Formula $\left\{ Y^{-1}\left(\left(-\infty,y\right]\right)\right\} _{y\in\R}$
\end_inset

 are 
\begin_inset Formula $\pi-$
\end_inset

systems (since intersections and preimages commute) that generate 
\begin_inset Formula $\sigma\left(X\right)$
\end_inset

 and 
\begin_inset Formula $\sigma\left(Y\right)$
\end_inset

 , respectively.
 The result then follows by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:indepSigmaAlgebras"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
The generalization of this result to the arbitrary collection of independent
 random variables proceeds in the obvious way.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:indepExpectationFactors"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probabiltiy space and let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be non-negative (or integrable) independent random variables.
 Then,
\begin_inset Formula 
\[
\E\left[XY\right]=\E\left[X\right]\E\left[Y\right].
\]

\end_inset


\end_layout

\begin_layout Proof
First suppose 
\begin_inset Formula $X,Y\geq0$
\end_inset

 almost surely.
 Note that
\begin_inset Formula 
\begin{align*}
\E\left[XY\right] & =\E_{X,Y}\left[xy\right]\\
 & =\E_{X}\left[\E_{Y}\left[xy\right]\right]\\
 & =\E_{X}\left[x\right]\E_{Y}\left[y\right]\\
 & =\E\left[X\right]\E\left[Y\right]
\end{align*}

\end_inset

where in the first equality we have moved to the image measure under the
 random vector 
\begin_inset Formula $\left(X,Y\right)$
\end_inset

 through the standard change of variables (Corollary 
\begin_inset CommandInset ref
LatexCommand ref
reference "cor:changeOfVariables"
plural "false"
caps "false"
noprefix "false"

\end_inset

).
 Then, since the image measure under the pair of independent random vectors
 is a product measure, we can use Tonelli's theorem to turn it into an iterated
 integral.
 The final equality is yet another application of the change of variables
 formula.
 Now if 
\begin_inset Formula $X,Y\in\Lp 1{\P},$
\end_inset

 then we can apply the result for non-negative random variables to 
\begin_inset Formula $\lvert X\rvert,\lvert Y\rvert$
\end_inset

 to show that 
\begin_inset Formula 
\[
\E\left[\lvert XY\rvert\right]=\E\left[\lvert X\rvert\right]\E\left[\lvert Y\rvert\right]<\infty
\]

\end_inset

and then applying the same argument (except replacing the use of Tonelli
 with the use of Fubini) yields the result.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2008samplepsb5"

\end_inset

 Consider the i.i.d.
 sequence 
\begin_inset Formula 
\[
X_{1},X_{2},X_{3},X_{4},X_{5},X_{6}
\]

\end_inset

 where each 
\begin_inset Formula $X_{i}$
\end_inset

 is one of the four symbols 
\begin_inset Formula $\{a,t,g,c\}$
\end_inset

.
 Further suppose that 
\begin_inset Formula 
\[
\begin{array}{ll}
P\left(X_{1}=a\right)=0.1 & P\left(X_{1}=t\right)=0.2\\
P\left(X_{1}=g\right)=0.3 & P\left(X_{1}=c\right)=0.4.
\end{array}
\]

\end_inset


\end_layout

\begin_layout Example
Let 
\begin_inset Formula $Z$
\end_inset

 denote the random variable that counts the number of times that the subsequence
 cat occurs (i.e.
 the letters 
\begin_inset Formula $c,a$
\end_inset

 and 
\begin_inset Formula $t$
\end_inset

 occur consecutively and in the correct order) in the above sequence.
 Find 
\begin_inset Formula $\E\left[Z\right]$
\end_inset

.
\end_layout

\begin_layout Solution*
Let 
\begin_inset Formula $Y_{i}=\indicate\left\{ X_{i}=c\right\} \indicate\left\{ X_{i+1}=a\right\} \indicate\left\{ X_{i+2}=t\right\} $
\end_inset

 for 
\begin_inset Formula $1\leq i\leq4$
\end_inset

 and notice that 
\begin_inset Formula $Z=\sum_{i=1}^{4}Y_{i}$
\end_inset

 and so 
\begin_inset Formula 
\begin{align*}
\E\left[Z\right] & =\sum_{i=1}^{4}\E\left[Y_{i}\right]\\
 & =\sum_{i=1}^{4}\P\left(X_{i}=c\right)\P\left(X_{i+1}=a\right)\P\left(X_{i+1}=t\right)\\
 & =4\times0.4\times0.1\times0.2\\
 & =0.032
\end{align*}

\end_inset

where we used independence in the second equality.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2005samplepsb2"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be independent random variables with 
\begin_inset Formula $X$
\end_inset

 having a 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[subsec:binomialDistribution]{binomial distribution}
\end_layout

\end_inset

 with parameters 
\begin_inset Formula $n_{1}$
\end_inset

 and 
\begin_inset Formula $p_{1}$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 having a binomial distribution with parameters 
\begin_inset Formula $n_{2}$
\end_inset

 and 
\begin_inset Formula $p_{2}$
\end_inset

.
 What is the probability that 
\begin_inset Formula $|X-Y|$
\end_inset

 is even? Well, we don't need to really worry about the absolute value sign
 since if 
\begin_inset Formula $X-Y$
\end_inset

 is even then 
\begin_inset Formula $Y-X$
\end_inset

 is even.
 Moreover, we know that 
\begin_inset Formula $X-Y$
\end_inset

 is even if and only if either both 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are even or both 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 are odd.
 Therefore, formally letting 
\begin_inset Formula $E:=\left\{ 0,2,4,\ldots\right\} $
\end_inset

 and 
\begin_inset Formula $O:=\left\{ 1,3,5,\ldots\right\} $
\end_inset


\begin_inset Formula 
\begin{align*}
\P\left(\lvert X-Y\rvert\in E\right) & =\P\left(X\in E,Y\in E\right)+\P\left(X\in O,Y\in O\right)\\
 & =\P\left(X\in E\right)\P\left(Y\in E\right)+\P\left(X\in O\right)\P\left(Y\in O\right)\\
 & =\sum_{l\in E}\left(\begin{array}{c}
n_{1}\\
l
\end{array}\right)p_{1}^{l}\left(1-p_{1}\right)^{n_{1}-l}\sum_{k\in E}\left(\begin{array}{c}
n_{2}\\
k
\end{array}\right)p_{2}^{k}\left(1-p_{2}\right)^{n_{1}-k}\\
 & \ \ +\sum_{l\in O}\left(\begin{array}{c}
n_{1}\\
l
\end{array}\right)p_{1}^{l}\left(1-p_{1}\right)^{n_{1}-l}\sum_{k\in O}\left(\begin{array}{c}
n_{2}\\
k
\end{array}\right)p_{2}^{k}\left(1-p_{2}\right)^{n_{1}-k}
\end{align*}

\end_inset


\end_layout

\begin_layout Subsection
Multiple random variables and random vectors
\end_layout

\begin_layout Standard
Most of the results that we have deduced for random variables hold 
\emph on
mutis mutandis 
\emph default
for random vectors, although some ideas need clarification in this more
 general context.
 For instance, the notion of a CDF is not immediately obvious since there
 is no canonical ordering on 
\begin_inset Formula $\R^{n}$
\end_inset

 for 
\begin_inset Formula $n>1.$
\end_inset


\end_layout

\begin_layout Subsection
Transformations of random variables
\end_layout

\begin_layout Standard
A typical question in basic probability theory is trying to find the distributio
n of some transformation of a collection of random variables.
 More formally, given random variables 
\begin_inset Formula $X_{1},X_{2},\ldots,X_{n}$
\end_inset

, on some probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

, we wish to find the distribution of 
\begin_inset Formula $T\left(X_{1},X_{2},\ldots,X_{n}\right)$
\end_inset

 where 
\begin_inset Formula $T:\R^{n}\to\R^{m}$
\end_inset

 is a Borel-measurable map.
\end_layout

\begin_layout Subsubsection
Transformations on scalar random variables
\end_layout

\begin_layout Subsubsection
Adding independent random variables
\end_layout

\begin_layout Standard
The simplest transformation we make on a collection of random variables
 is simply adding them.
 The theory of 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[subsec:convolutions]{convolutions}
\end_layout

\end_inset

 we developed in Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:productMeasures"
plural "false"
caps "false"
noprefix "false"

\end_inset

 gives us the tools to find the distribution of the sum of random variables.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:distSumIndep"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be 
\begin_inset Formula $\Lp1{\P}$
\end_inset

 (or non-negative) independent random variables on the space.
 Then, the distribution of 
\begin_inset Formula $Z:=X+Y$
\end_inset

 is given by 
\begin_inset Formula 
\[
\P_{Z}\left(B\right)=\E_{Y}\left[\P_{X}\left(B-y\right)\right].
\]

\end_inset

for any 
\begin_inset Formula $B\in\borel\left(\R\right).$
\end_inset

 In particular, the CDF
\begin_inset Formula 
\[
F_{Z}\left(z\right)=\E_{Y}\left[F_{X}\left(z-y\right)\right]
\]

\end_inset


\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula 
\begin{align*}
\P_{Z}\left(B\right) & =\E_{Y}\left[\E_{X}\left[\indicate_{B}\left(x+y\right)\right]\right]\\
 & =\E_{Y}\left[\E_{X}\left[\indicate_{B-y}\left(x\right)\right]\right]\\
 & =\E_{Y}\left[\P_{X}\left(B-y\right)\right]
\end{align*}

\end_inset

 since 
\begin_inset Formula $x+y\in B\Longleftrightarrow x\in B-y$
\end_inset

.
 Of course, when 
\begin_inset Formula $B=\left(-\infty,z\right]$
\end_inset

 the result about CDFs follows.
\end_layout

\begin_layout Corollary
\begin_inset CommandInset label
LatexCommand label
name "cor:discreteConvolution"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be 
\begin_inset Formula $\Lp1{\P}$
\end_inset

 (or non-negative) independent and discrete random variables supported on
 some countable set 
\begin_inset Formula $S$
\end_inset

.
 Then, the distribution of 
\begin_inset Formula $Z:=X+Y$
\end_inset

 is given 
\begin_inset Formula 
\[
\P\left(Z=z\right)=\sum_{y\in S}\P\left(Y=y\right)\mathbb{P}\left(X=z-y\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $B=\left\{ z\right\} $
\end_inset

 in Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:distSumIndep"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2007samplepsb5"

\end_inset

Let 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

 be i.i.d.
 random variables, with 
\begin_inset Formula $P(X=k)=2^{-k}$
\end_inset

 for 
\begin_inset Formula $k=1,2,3,\ldots$
\end_inset

 Find 
\begin_inset Formula $P(X>Y)$
\end_inset

 and 
\begin_inset Formula $P(X>2Y)$
\end_inset

.
 The trick here is to define 
\begin_inset Formula $Z:=X-\alpha Y$
\end_inset

 for 
\begin_inset Formula $\alpha>0$
\end_inset

 and note that
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(Z=z\right) & =\sum_{y\in\N}\P\left(Y=y\right)\mathbb{P}\left(X=z+\alpha y\right)\\
 & =\sum_{y\in\N}2^{-y}2^{-\left(z+\alpha y\right)}\indicate\left\{ z+\alpha y\geq1\right\} \\
 & =2^{-z}\sum_{y\in\N}2^{-\left(1+\alpha\right)y}\indicate\left\{ y\geq\frac{1-z}{\alpha}\right\} \\
 & =2^{-z}\sum_{y=\max\left\{ 1,\lceil\frac{1-z}{\alpha}\rceil\right\} }^{\infty}2^{-\left(1+\alpha\right)y}.
\end{align*}

\end_inset

For 
\begin_inset Formula $\alpha=1$
\end_inset

, the above reduces to 
\begin_inset Formula $\P\left(Z=z\right)=\frac{2^{-z}}{3}$
\end_inset

 and so 
\begin_inset Formula $\P\left(Z\geq0\right)=\sum_{z=0}^{\infty}\frac{2^{-z}}{3}=\frac{2}{3}.$
\end_inset

 If 
\begin_inset Formula $\alpha=2$
\end_inset

 then 
\begin_inset Formula $\P\left(Z=z\right)=\frac{2^{-z}}{7}$
\end_inset

 and so 
\begin_inset Formula $\P\left(Z\geq0\right)=\sum_{z=0}^{\infty}\frac{2^{-z}}{7}=\frac{2}{7}.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
More often than not, we are dealing with a situation where we are adding
 random variables that are not of the same 
\begin_inset Quotes eld
\end_inset

type
\begin_inset Quotes erd
\end_inset

, as is the case in the following example.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2005samplepsb5"

\end_inset

Suppose 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $U$
\end_inset

 are independent random variables with 
\begin_inset Formula 
\[
P(X=k)=\frac{1}{N+1},\quad k=0,1,2,\ldots,N,
\]

\end_inset

 and 
\begin_inset Formula $U$
\end_inset

 having a uniform distribution on 
\begin_inset Formula $[0,1]$
\end_inset

.
 Let 
\begin_inset Formula $Y=X+U$
\end_inset

.
 What is the distribution of 
\begin_inset Formula $Y$
\end_inset

? What is the Pearson correlation coefficient 
\begin_inset Formula $r_{Y,X}$
\end_inset

? First note that by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:distSumIndep"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset Formula 
\begin{align*}
F_{Y}\left(y\right) & =\E_{X}\left[F_{U}\left(y-x\right)\right]\\
 & =\E_{X}\left[\left(y-x\right)\indicate\left\{ y-1\leq x\leq y\right\} +\indicate\left\{ x<y-1\right\} \right]\\
 & =\frac{1}{N+1}\sum_{x=0}^{N}\left(y-x\right)\indicate\left\{ y-1\leq x\leq y\right\} +\frac{1}{N+1}\sum_{x=0}^{N}\indicate\left\{ x<y-1\right\} \\
 & =\frac{y-\lfloor y\rfloor}{N+1}\indicate\left\{ 0\leq y\leq N+1\right\} +\frac{\lfloor y\rfloor}{N+1}\indicate\left\{ 0\leq y\leq N+1\right\} +\indicate\left\{ y>N+1\right\} \\
 & =\frac{y}{N+1}\indicate\left\{ 0\leq y\leq N+1\right\} +\indicate\left\{ y>N+1\right\} .
\end{align*}

\end_inset

For the correlation between 
\begin_inset Formula $X$
\end_inset

 and 
\begin_inset Formula $Y$
\end_inset

, note that 
\begin_inset Formula 
\begin{align*}
\Cov\left[X+U,X\right] & =\Var\left[X\right]\\
 & =
\end{align*}

\end_inset

and 
\begin_inset Formula $\Var\left[Y\right]=\Var\left[X\right]+\Var\left[U\right]$
\end_inset

 and so 
\begin_inset Formula 
\[
r_{X,Y}=\frac{\Var\left[X\right]}{\Var\left[X\right]+\Var\left[U\right]}
\]

\end_inset


\end_layout

\begin_layout Example
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection
Products of random variables
\end_layout

\begin_layout Subsubsection
Absolute values of random variables
\end_layout

\begin_layout Subsection
Order statistics
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2007samplepsb8"

\end_inset

Let 
\begin_inset Formula $U_{1},U_{2},\ldots,U_{n}$
\end_inset

 be i.i.d.
 uniform 
\begin_inset Formula $(0,1)$
\end_inset

 random variables and suppose 
\begin_inset Formula 
\[
X=\max\left(U_{1},U_{2},\ldots,U_{n}\right)\text{ and }Y=\min\left(U_{1},U_{2},\ldots,U_{n}\right).
\]

\end_inset


\end_layout

\begin_layout Example
Find the distribution of 
\begin_inset Formula $Z=X-Y$
\end_inset

.
 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Concentration inequalities
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2015psb5ptB"

\end_inset

Consider the setting in Example 
\begin_inset CommandInset ref
LatexCommand ref
reference "exa:isi2015psb5ptA"
plural "false"
caps "false"
noprefix "false"

\end_inset

 again.
 Can we provide a bound for 
\begin_inset Formula $\E\left[\lvert X+Y\rvert\right]$
\end_inset

 with the additional information that 
\begin_inset Formula $\mathbb{E}\left[X+Y\right]=\mathbb{E}\left[X-Y\right]=0$
\end_inset

? Note that in this case 
\begin_inset Formula $\E\left[X\right]=\E\left[Y\right]=0$
\end_inset

 and so 
\begin_inset Formula $\Var\left[X+Y\right]=\E\left[\left(X+Y\right)^{2}\right]=3$
\end_inset

 and so by 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hyperref[thm:jensenInequality]{Jensen's inequality}
\end_layout

\end_inset

 and the fact that 
\begin_inset Formula $x\to\sqrt{x}$
\end_inset

 is concave, we have that
\begin_inset Formula 
\[
\E\left[\lvert X+Y\rvert\right]\leq\sqrt{\E\left[\left(X+Y\right)^{2}\right]}=\sqrt{3}.
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2016psa26"

\end_inset


\begin_inset Argument 1
status collapsed

\begin_layout Plain Layout
ISI 2016 PSA 26
\end_layout

\end_inset

Two integers 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 are chosen at random with replacement from 
\begin_inset Formula $\{1,2,\ldots,9\}$
\end_inset

.
 What is the probabiliy that that 
\begin_inset Formula $m^{2}-n^{2}$
\end_inset

 is even? First note that 
\begin_inset Formula $m^{2}-n^{2}=\left(m+n\right)\left(m-n\right)$
\end_inset

 so we need to either 
\begin_inset Formula $m+n$
\end_inset

 or 
\begin_inset Formula $m-n$
\end_inset

 to be even.
 For this to be true, both 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 need to be even, or both odd.
 The probability that they are both even is 
\begin_inset Formula $\frac{4}{9}\times\frac{4}{9}=\frac{16}{81}$
\end_inset

 since sampling with replacement leads to indepenent events.
 The probability that they are both odd is similarly 
\begin_inset Formula $\frac{5}{9}\times\frac{5}{9}=\frac{25}{81}.$
\end_inset

 Thus the probability that they are either both odd or even is 
\begin_inset Formula $\frac{16+25}{81}=\frac{41}{81}.$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2004samplepsb4"

\end_inset

Two policemen are sent to watch a road that is 
\begin_inset Formula $1\mathrm{~km}$
\end_inset

 long.
 Each of the two policemen is assigned a position on the road which is chosen
 according to a uniform distribution along the length of the road and independen
t of the other's position.
 Find the probability that the policemen will be less than 
\begin_inset Formula $1/4$
\end_inset

 kilometer apart when they reach their assigned posts.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2004samplepsb7"

\end_inset

Suppose 
\begin_inset Formula $X$
\end_inset

 has a normal distribution with mean 0 and variance 25 .
 Let 
\begin_inset Formula $Y$
\end_inset

 be an independent random variable taking values -1 and 1 with equal probability.
 Define
\begin_inset Formula $S=XY+\frac{X}{Y}$
\end_inset

 and
\begin_inset Formula $T=XY-\frac{X}{Y}$
\end_inset

.
 (a) Find the probability distribution of 
\begin_inset Formula $S$
\end_inset

.
 (b) Find the probability distribution of 
\begin_inset Formula $\left(\frac{S+T}{10}\right)^{2}$
\end_inset

.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2006samplepsb3"

\end_inset

Let 
\begin_inset Formula $X_{1},X_{2}\ldots$
\end_inset

 be i.i.d.
 Bernoulli random variables with parameter 
\begin_inset Formula $\frac{1}{4}$
\end_inset

, let 
\begin_inset Formula $Y_{1},Y_{2},\ldots$
\end_inset

 be another sequence of i.i.d.
 Bernoulli random variables with parameter 
\begin_inset Formula $\frac{3}{4}$
\end_inset

 and Let 
\begin_inset Formula $N$
\end_inset

 be a geometric random variable with parameter 
\begin_inset Formula $\frac{1}{2}$
\end_inset

 (i.
 e.
 
\begin_inset Formula $P(N=k)=\frac{1}{2^{k}}$
\end_inset

for 
\begin_inset Formula $k=1,2\ldots)$
\end_inset

.
 Assume the 
\begin_inset Formula $X_{i}$
\end_inset

 's, 
\begin_inset Formula $Y_{j}$
\end_inset

's and 
\begin_inset Formula $N$
\end_inset

 are all independent.
 Compute 
\begin_inset Formula $\Cov\left(\sum_{i=1}^{N}X_{i},\sum_{i=1}^{N}Y_{i}\right)$
\end_inset

.
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
hl{TODO}
\end_layout

\end_inset


\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\end_body
\end_document
