#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass amsbook
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Independence
\end_layout

\begin_layout Standard
Formal probability theory is often described as measure theory (or more
 generally, analysis) on measure spaces 
\begin_inset Formula $\measurespace$
\end_inset

 where the 
\begin_inset Formula $\mu\left(\X\right)=1$
\end_inset

 and to a certain extent the foundational theory does resemble this characteriza
tion.
 However probability itself is distinct from foundational probability 
\emph on
theory
\emph default
, in that its goals and aims are to solve problems that are of a fundamentally
 different character than problems seen in analysis.
\end_layout

\begin_layout Standard
Probability as as subject has a strong combinatorial flavor, since it owes
 its origins to gambling and games of chance considered by amateur mathematician
s in the 17th and 18th centuries.
 These classical ideas still permeate the modern 
\emph on
probabilistic way of thinking.

\emph default
 As such, it would be useful to revise the basic combinatorial tools that
 are indispensable when tackling problems of this nature.
 These are discussed in Appendix 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:Combinatorics"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Standard
In general, we can say that probability theory 
\begin_inset Quotes eld
\end_inset

has a right hand and a left hand
\begin_inset Quotes erd
\end_inset

.
 The right hand is the rigorous measure-theoretic axiomatization that one
 encounters in a course on probability theory.
 The left hand is the probablistic intuition that one develops through trying
 to model stochastic phenomena with the aforementioned probabilistic way
 of thinking.
 Probabilists aim to be ambidextrous in this regard, using the axiomatic
 framework of probability theory to deduce facts about processes whose parts
 and subparts can be reduced to “naïve” probabilistic concepts.
\end_layout

\begin_layout Standard
In order to cover both parts of probability adequately, we will use the
 background in analysis developed in Part I of these notes to prove general
 theorems, while using numerous examples to develop probabilistic intuition.
 I hope that the combination of theory and examples prove sufficient in
 painting a vivid picture of probability theory, with a view towards application
s in statistics and economics.
\end_layout

\begin_layout Section
Probability spaces and probability measures
\end_layout

\begin_layout Standard
While formal probability theory is based on measure theory, the language
 of probability theory is different.
 To start our exploration into probability theory, we shall first have to
 translate a lot of the basic terminology of measure theory into the langauge
 of probability.
 To begin with, we specialize the notion of a measure space 
\begin_inset Formula $\measurespace$
\end_inset

 to a probability space 
\begin_inset Formula $\probabilityspace$
\end_inset

 where 
\begin_inset Formula $\mathbb{P}\left(\Omega\right)=1$
\end_inset

.
 Measurable sets 
\begin_inset Formula $A\in\F$
\end_inset

 are called 
\emph on
events 
\emph default
in the language of probability.
 The basic properties of probability measures carry over from Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:measures"
plural "false"
caps "false"
noprefix "false"

\end_inset

; we list a few more for completeness.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:inclusionExclusionProbability"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
Inclusion-Exclusion
\end_layout

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}\in\F$
\end_inset

.
 Then
\begin_inset Formula 
\[
\mathbb{P}\left(\bigcup_{i=1}^{n}A_{i}\right)=\sum_{i=1}^{n}\left(-1\right)^{i-1}\sum_{J\subset\left\{ 1,2,\ldots n\right\} ,\lvert J\rvert=i}\mathbb{P}\left(\bigcap_{j\in J}A_{j}\right).
\]

\end_inset


\end_layout

\begin_layout Proof
Integrate the equality 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq:inclusionExclusionIndicator"
plural "false"
caps "false"
noprefix "false"

\end_inset

 in Lemma 
\begin_inset CommandInset ref
LatexCommand eqref
reference "lem:inclusionExclusion"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2017psa23"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2017 PSA 23
\end_layout

\end_inset

Three numbers are chosen at random from 
\begin_inset Formula $\{1,2,\ldots,10\}$
\end_inset

 without replacement.
 What is the probability that the minimum of the chosen numbers is 
\begin_inset Formula $3$
\end_inset

 or their maximum is 
\begin_inset Formula $7$
\end_inset

 ? Let 
\begin_inset Formula $A$
\end_inset

 be the event that we select three numbers with minimum 
\begin_inset Formula $3$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 be the event that we select three numbers with maximum 
\begin_inset Formula $7$
\end_inset

.
 We want 
\begin_inset Formula $\mathbb{P}\left(A\cup B\right)=\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)-\mathbb{P}\left(A\cap B\right).$
\end_inset

 We need to compute each component.
 To compute the first term, note that there are 
\begin_inset Formula $\left(\begin{array}{c}
7\\
2
\end{array}\right)$
\end_inset

 ways to pick 2 numbers without replacement after fixing the first one at
 3 since we are picking only from the remaining numbers which are greater
 than three.
 Therefore 
\begin_inset Formula $\mathbb{P}\left(A\right)=\left(\begin{array}{c}
7\\
2
\end{array}\right)/\left(\begin{array}{c}
10\\
3
\end{array}\right).$
\end_inset

 Similarly, we have that 
\begin_inset Formula $\mathbb{P}\left(B\right)=\left(\begin{array}{c}
6\\
2
\end{array}\right)/\left(\begin{array}{c}
10\\
3
\end{array}\right).$
\end_inset

 To find the intersection, note that after fixing 
\begin_inset Formula $3$
\end_inset

 and 
\begin_inset Formula $7$
\end_inset

 there are only 4 choices of the middle number, leaving us with 
\begin_inset Formula $\mathbb{P}\left(A\cap B\right)=$
\end_inset


\begin_inset Formula $4/\left(\begin{array}{c}
10\\
3
\end{array}\right)$
\end_inset

.
 In sum,
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\right) & =\frac{\left(\begin{array}{c}
7\\
2
\end{array}\right)+\left(\begin{array}{c}
6\\
2
\end{array}\right)-4}{\left(\begin{array}{c}
10\\
3
\end{array}\right)}\\
 & =\frac{21+15-4}{120}\\
 & =\frac{4}{15}.
\end{align*}

\end_inset


\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:bonferroniInequality"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A_{1},A_{2},\ldots,A_{n}\in\F$
\end_inset

.
 Then
\begin_inset Formula 
\[
\mathbb{P}\left(\bigcap_{i=1}^{n}A_{i}\right)\geq\sum_{i=1}^{n}\mathbb{P}\left(A_{i}\right)-(n-1).
\]

\end_inset


\end_layout

\begin_layout Proof
First note that for 
\begin_inset Formula $n=2$
\end_inset

, the result follows due to the fact that for any 
\begin_inset Formula $A,B\in\F$
\end_inset


\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\right) & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)-\mathbb{P}\left(A\cap B\right)\\
 & \leq\mathbb{P}\left(\Omega\right)\\
 & =1.
\end{align*}

\end_inset

Now assume the induction hypothesis and note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(\bigcap_{i=1}^{n}A_{i}\right) & =\mathbb{P}\left(\bigcap_{i=1}^{n-1}A_{i}\cap A_{n}\right)\\
 & \geq\mathbb{P}\left(\bigcap_{i=1}^{n-1}A_{i}\right)+\mathbb{P}\left(A_{n}\right)-1\\
 & \geq\sum_{i=1}^{n-1}\mathbb{P}\left(A_{i}\right)-(n-2)+\mathbb{P}\left(A_{n}\right)-1\\
 & =\sum_{i=1}^{n}\mathbb{P}\left(A_{i}\right)-\left(n-1\right).
\end{align*}

\end_inset


\end_layout

\begin_layout Section
Independent events
\end_layout

\begin_layout Standard
In Chapter 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:productMeasures"
plural "false"
caps "false"
noprefix "false"

\end_inset

 we discussed the notion of product measures; the analagous concept in probabili
ty is that of independence.
 Informally, we think of independent events as those where the occurence
 or non-occurenece of one event does not impact the occurence or non-occurence
 of another.
 We can formalize this idea with the following definition-
\end_layout

\begin_layout Definition
\begin_inset CommandInset label
LatexCommand label
name "def:independence"

\end_inset

Let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 Then a collection of events
\emph on
 
\emph default

\begin_inset Formula $\left\{ A_{i}\right\} _{i\in I}\subset\F$
\end_inset

 are independent if for every finite subset 
\begin_inset Formula $J\subset I$
\end_inset


\begin_inset Formula 
\[
\mathbb{P}\left[\bigcap_{j\in J}A_{j}\right]=\prod_{j\in J}\mathbb{P}\left[A_{j}\right].
\]

\end_inset

Two independent events 
\begin_inset Formula $A,B\in\F$
\end_inset

 are often denoted 
\begin_inset Formula $A\indep B$
\end_inset

.
\end_layout

\begin_layout Standard
Notice how the index set 
\begin_inset Formula $I$
\end_inset

 was arbitrary and so we can have countable or uncountable collections of
 independent events.
 Of course, this notion isn't particualrly interesting unless we have some
 rich examples of such events and the probability spaces they live in.
 More generally, we have a question of existence: do independent events
 always exist, no matter the probability space? The answer to this question
 is trivially yes since 
\begin_inset Formula $\mathbb{P}\left(\Omega\cap\emptyset\right)=\mathbb{P}\left(\Omega\right)\mathbb{P}\left(\emptyset\right)=0.$
\end_inset

 So then the question reduces to asking whether 
\emph on
non-trivial 
\emph default
independent events always exist.
 Here of course, the answer is 
\begin_inset Quotes eld
\end_inset

no
\begin_inset Quotes erd
\end_inset

, since for 
\begin_inset Formula $\F=\left\{ \emptyset,A,A^{C},\Omega\right\} $
\end_inset

 where 
\begin_inset Formula $0<\mathbb{P}\left(A\right)<1$
\end_inset

, we have that 
\begin_inset Formula $\mathbb{P}\left(A\cap A^{C}\right)=0$
\end_inset

 but 
\begin_inset Formula $\mathbb{P}\left(A\right)\mathbb{P}\left(A^{C}\right)=\mathbb{P}\left(A\right)\left(1-\mathbb{P}\left(A\right)\right)\neq0.$
\end_inset

 Nevertheless, we have a rich collection of examples of independent events:
 think about rolling a dice twice and observing a six in each roll; these
 event of seeing a six in the first roll is independent of the event of
 seeing one in the next roll.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2017psa15"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2017 PSA 15
\end_layout

\end_inset

Suppose that the events 
\begin_inset Formula $A,B$
\end_inset

, and 
\begin_inset Formula $C$
\end_inset

 are pairwise independent such that each of them occurs with probability
 
\begin_inset Formula $p$
\end_inset

.
 Assume that all three of them cannot occur simultaneously.
 What is 
\begin_inset Formula $P(A\cup B\cup C)$
\end_inset

 ? Well, we apply independence and inclusion exclusion to note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cup B\cup C\right) & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)+\mathbb{P}\left(C\right)-\mathbb{P}\left(A\cap B\right)-\mathbb{P}\left(A\cap C\right)-\mathbb{P}\left(B\cap C\right)\\
 & =\mathbb{P}\left(A\right)+\mathbb{P}\left(B\right)+\mathbb{P}\left(C\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(B\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(C\right)-\mathbb{P}\left(B\right)\mathbb{P}\left(C\right)\\
 & =3p(1-p).
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
The canonical example of the an infinite collection of independent events
 is given by the following description of an infinitely repeated experiment.
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:infinitelyRepeatedExperiment"

\end_inset

Let 
\begin_inset Formula $E$
\end_inset

 consist of a finite set of outcomes and let 
\begin_inset Formula $\Omega=E^{\N}$
\end_inset

 be the collection of 
\begin_inset Formula $E$
\end_inset

-valued sequences.
 Thus for any 
\begin_inset Formula $\omega\in\Omega$
\end_inset

, we can write
\begin_inset Formula 
\[
\omega=\left(\omega_{1},\omega_{2},\ldots\right)
\]

\end_inset

where 
\begin_inset Formula $\omega_{i}\in E$
\end_inset

.
 We can then construct the collection
\begin_inset Formula 
\[
\left[\omega_{1}^{*},\ldots,\omega_{n}^{*}\right]:=\left\{ \omega\in\Omega\mid\omega_{i}=\omega_{i}^{*},1\leq i\leq n\right\} 
\]

\end_inset


\end_layout

\begin_layout Lemma
\begin_inset CommandInset label
LatexCommand label
name "lem:independenceComplements"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $A,B\in\F$
\end_inset

 be events.
 Then the claims that 
\begin_inset Formula $A,B$
\end_inset

 are independent, 
\begin_inset Formula $A,B^{C}$
\end_inset

 are independent, 
\begin_inset Formula $A^{C},B$
\end_inset

 are independent, and 
\begin_inset Formula $A^{C},B^{C}$
\end_inset

are independent are equivalent.
\end_layout

\begin_layout Proof
Note that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}\left(A\cap B^{C}\right) & =\mathbb{P}\left(A\setminus B\right)\\
 & =\mathbb{P}\left(A\setminus A\cap B\right)\\
 & =\mathbb{P}\left(A\right)-\mathbb{P}\left(A\cap B\right)\\
 & =\mathbb{P}\left(A\right)-\mathbb{P}\left(A\right)\mathbb{P}\left(B\right)\\
 & =\mathbb{P}\left(A\right)\left(1-\mathbb{P}\left(B\right)\right)\\
 & =\mathbb{P}\left(A\right)\mathbb{P}\left(B^{C}\right)
\end{align*}

\end_inset

where the fourth equality uses independence.
 Then it should be clear that 
\begin_inset Formula $A^{C}$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 are independent exactly for the same reason.
 Finally, we can apply the logic above using 
\begin_inset Formula $A^{C}$
\end_inset

and 
\begin_inset Formula $B$
\end_inset

 instead of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $B$
\end_inset

 to get that 
\begin_inset Formula $A^{C}$
\end_inset

 and 
\begin_inset Formula $B^{C}$
\end_inset

 are independent.
\end_layout

\begin_layout Proposition
\begin_inset CommandInset label
LatexCommand label
name "prop:independenceFacts"

\end_inset

Let 
\begin_inset Formula $\probabilityspace$
\end_inset

 be a probability space and let 
\begin_inset Formula $I$
\end_inset

 be an arbitrary index set.
 Let 
\begin_inset Formula $\left\{ A_{i}\right\} _{i\in I}\in\F$
\end_inset

 be a collection of events and define 
\begin_inset Formula $B_{i}^{1}=A_{i}^{C}$
\end_inset

 and 
\begin_inset Formula $B_{i}^{0}=A_{i}.$
\end_inset

 Then, the following statements are equivalent
\end_layout

\begin_layout Proposition
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{enumerate}[label=(
\backslash
roman*),leftmargin=.1
\backslash
linewidth,rightmargin=.4
\backslash
linewidth]
\end_layout

\begin_layout Plain Layout


\backslash
item $
\backslash
left
\backslash
{ A_{i}
\backslash
right
\backslash
} _{i
\backslash
in I}
\backslash
in
\backslash
F$ are independent events.
\end_layout

\begin_layout Plain Layout


\backslash
item There exists some $
\backslash
alpha 
\backslash
in 
\backslash
{0,1
\backslash
}^I$ such that $
\backslash
{B_i^{a(i)}
\backslash
}$ are independent.
\end_layout

\begin_layout Plain Layout


\backslash
item For every $
\backslash
alpha 
\backslash
in 
\backslash
{0,1
\backslash
}^I$, $
\backslash
{B_i^{a(i)}
\backslash
}$ are independent.
 
\end_layout

\begin_layout Plain Layout


\backslash
end{enumerate}
\end_layout

\end_inset


\end_layout

\begin_layout Proof
(Sketch) Note that if 
\emph on
(i) 
\emph default
holds, then 
\emph on
(ii)
\emph default
 holds automatically with 
\begin_inset Formula $a\left(i\right)=0$
\end_inset

 for all 
\begin_inset Formula $i\in I$
\end_inset

.
 Similarly, if 
\begin_inset Formula $(iii)$
\end_inset

 holds then 
\begin_inset Formula $(i)$
\end_inset

 holds trivially.
 Thus we need to prove that 
\begin_inset Formula $(ii)\implies(iii)$
\end_inset

.
 First, fix 
\begin_inset Formula $\alpha\in\{0,1\}^{I}$
\end_inset

 such that our claim holds.
 Notice that by Lemma 
\begin_inset CommandInset ref
LatexCommand ref
reference "lem:independenceComplements"
plural "false"
caps "false"
noprefix "false"

\end_inset

, for any 
\begin_inset Formula $J\subset I$
\end_inset

 such that 
\begin_inset Formula $\lvert J\rvert=2$
\end_inset

,
\begin_inset Formula 
\[
\mathbb{P}\left(\prod_{j\in J}B_{j}^{\gamma(j)}\right)=\prod_{j\in J}\mathbb{P}\left(B_{j}^{\gamma\left(j\right)}\right)
\]

\end_inset

for any 
\begin_inset Formula $\gamma\in\left\{ 0,1\right\} ^{I}$
\end_inset

.
 For induction, suppose that the claim holds for any 
\begin_inset Formula $J\subset I$
\end_inset

 such that 
\begin_inset Formula $\lvert J\rvert=n$
\end_inset

 and the consider a subset 
\begin_inset Formula $J^{\prime}\subset I$
\end_inset

 with 
\begin_inset Formula $\lvert J^{\prime}\rvert=n+1$
\end_inset

.
 Note that for any 
\begin_inset Formula $i\in J^{\prime}$
\end_inset

, we can define 
\begin_inset Formula $B_{-i}:=\bigcap_{j\in J^{\prime}\setminus\left\{ i\right\} }B_{j}^{\alpha\left(j\right)}$
\end_inset

 and observe that 
\begin_inset Formula 
\[
\mathbb{P}\left(B_{-i}\cap B_{i}^{\alpha\left(i\right)}\right)=\mathbb{P}\left(B_{-i}\right)\mathbb{P}\left(B_{i}^{\alpha\left(i\right)}\right)
\]

\end_inset

and so 
\begin_inset Formula $B_{-i}\indep B_{i}^{\alpha\left(i\right)}$
\end_inset

 and so by our Lemma, 
\begin_inset Formula $B_{-i}\indep B_{i}^{\gamma\left(i\right)}.$
\end_inset

 The induction hypothesis then implies that 
\begin_inset Formula $\left\{ B_{j}^{\alpha\left(j\right)}\right\} ,B_{i}^{\gamma\left(i\right)}$
\end_inset

 are all mutually independent.
 We can yet again repeat this process with some 
\begin_inset Formula $i^{\prime}\in J^{\prime}$
\end_inset

 where now 
\begin_inset Formula $B_{-i^{\prime}}:=\bigcap_{j\in J^{\prime}\setminus\left\{ i,i^{\prime}\right\} }B_{j}^{\alpha\left(j\right)}\cap B_{i}^{\gamma\left(i\right)}$
\end_inset

 and so on until we have replaced all 
\begin_inset Formula $\alpha$
\end_inset

s with 
\begin_inset Formula $\gamma$
\end_inset

s.
\end_layout

\begin_layout Standard
This idea of mutual independence finds purchase in some unexpected contexts
 as well.
 For instance, we can use it to prove Euler's prime number formula.
\end_layout

\begin_layout Theorem
\begin_inset CommandInset label
LatexCommand label
name "thm:eulerPrime"

\end_inset

Let 
\begin_inset Formula $\mathcal{P}$
\end_inset

 denote the set of primes.
 The Riemann zeta function 
\begin_inset Formula 
\[
\zeta\left(s\right):=\sum_{n=1}^{\infty}n^{-s}
\]

\end_inset

has the representation
\begin_inset Formula 
\[
\zeta\left(s\right)=\prod_{p\in\mathcal{P}}\left(1-p^{-s}\right)^{-1}.
\]

\end_inset


\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\probabilityspace=\left(\N,2^{\N},\mathbb{P}_{s}\right)$
\end_inset

 where 
\begin_inset Formula $\mathbb{P}_{s}\left(\left\{ n\right\} \right)=\frac{n^{-s}}{\zeta\left(s\right)}$
\end_inset

 for 
\begin_inset Formula $s>1.$
\end_inset

 Define 
\begin_inset Formula $p\N:=\left\{ pn\mid n\in\N\right\} $
\end_inset

 and let 
\begin_inset Formula $ $
\end_inset

for any 
\begin_inset Formula $p\in\mathcal{P}$
\end_inset

 and notice that 
\begin_inset Formula $\mathbb{P}_{s}\left(p\N\right)=\sum_{n=1}^{\infty}\mathbb{P}\left(pn\right)=p^{-s}$
\end_inset

 by countable additivity.
 Then, for any distinct collection 
\begin_inset Formula $p_{1},\ldots,p_{k}\in\mathcal{P}$
\end_inset

 we have that 
\begin_inset Formula 
\begin{align*}
\mathbb{P}_{s}\left(\bigcap_{i=1}^{k}p_{i}\N\right) & =\sum_{n=1}^{\infty}\mathbb{P}_{s}\left(\prod_{i=1}^{k}pn\right)\\
 & =\prod_{i=1}^{k}p^{-s}\\
 & =\prod_{i=1}^{k}\mathbb{P}_{s}\left(p_{i}\N\right).
\end{align*}

\end_inset

In other words, the events 
\begin_inset Formula $\left\{ p\N\right\} _{p\in\mathcal{P}}$
\end_inset

are mutually independent and so by Proposition 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:independenceFacts"
plural "false"
caps "false"
noprefix "false"

\end_inset


\begin_inset Formula 
\begin{align*}
\frac{1}{\zeta\left(s\right)} & =\mathbb{P}_{s}\left(\left\{ 1\right\} \right)\\
 & =\mathbb{P}_{s}\left(\bigcap_{p\in\mathcal{P}}\left(p\N\right)^{C}\right)\\
 & =\lim_{n\to\infty}\mathbb{P}_{s}\left(\bigcap_{p\in\mathcal{P},p\leq n}\left(p\N\right)^{C}\right)\\
 & =\lim_{n\to\infty}\prod_{p\in\mathcal{P},p\leq n}\left(1-\mathbb{P}_{s}\left(p\N\right)\right)\\
 & =\lim_{n\to\infty}\prod_{p\in\mathcal{P},p\leq n}\left(1-p^{-s}\right)\\
 & =\prod_{p\in\mathcal{P}}\left(1-p^{-s}\right)
\end{align*}

\end_inset

where the second equality is due to the fact that 
\begin_inset Formula $1$
\end_inset

 is neither prime nor a product of primes, the third due to the continuity
 of measures (see Propositions 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:measureProperties"
plural "false"
caps "false"
noprefix "false"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "prop:equivalenceContinuityMeasures"
plural "false"
caps "false"
noprefix "false"

\end_inset

), and the fourth due the fact that 
\begin_inset Formula $\mathbb{P}_{s}\left(\N\right)=1.$
\end_inset


\end_layout

\begin_layout Section
Random variables
\end_layout

\begin_layout Example
\begin_inset CommandInset label
LatexCommand label
name "exa:isi2016psa26"

\end_inset


\begin_inset Argument 1
status open

\begin_layout Plain Layout
ISI 2016 PSA 26
\end_layout

\end_inset

Two integers 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 are chosen at random with replacement from 
\begin_inset Formula $\{1,2,\ldots,9\}$
\end_inset

.
 What is the probabiliy that that 
\begin_inset Formula $m^{2}-n^{2}$
\end_inset

 is even? First note that 
\begin_inset Formula $m^{2}-n^{2}=\left(m+n\right)\left(m-n\right)$
\end_inset

 so we need to either 
\begin_inset Formula $m+n$
\end_inset

 or 
\begin_inset Formula $m-n$
\end_inset

 to be even.
 For this to be true, both 
\begin_inset Formula $m$
\end_inset

 and 
\begin_inset Formula $n$
\end_inset

 need to be even, or both odd.
 The probability that they are both even is 
\begin_inset Formula $\frac{4}{9}\times\frac{4}{9}=\frac{16}{81}$
\end_inset

 since sampling with replacement leads to indepenent events.
 The probability that they are both odd is similarly 
\begin_inset Formula $\frac{5}{9}\times\frac{5}{9}=\frac{25}{81}.$
\end_inset

 Thus the probability that they are either both odd or even is 
\begin_inset Formula $\frac{16+25}{81}=\frac{41}{81}.$
\end_inset


\end_layout

\end_body
\end_document
